{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052125fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen from runs prior to run_2021_12_29-00_26_20 ForcedLearning20Cifar100Adam, the categorical\n",
    "#accuracy progresses much more slowly than the vanilla variant of the model. I hypothesize that this is\n",
    "#because the model has to play \"Catch-up\" with itself, because each block is learning independently. This\n",
    "#causes each successive block in the model to spend the next batch adjusting to what the previous batch just\n",
    "#learned, and not gaining any intelligence. I have rectified this by allowing each training step to have the\n",
    "#model pass through one layer, update that specific model_block, pass through another, update that block wrt\n",
    "#the first and second block, and so on. This has increased the time, but vastly increased the speed at which\n",
    "#the model learns, even surpassing the vanilla model at the beginning of the training.\n",
    "\n",
    "#This new forced learning seems to cap out at about 68 percent cat. accuracy, perhaps it is unable to learn\n",
    "#lower features? Perhaps it would fair well with a larger model, and different dataset. I think I should try\n",
    "#creating different optimizers with different learning rates for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bf7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "x_test, x_val = np.array_split(x_test, 2)\n",
    "y_test, y_val = np.array_split(y_test, 2)\n",
    "\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_val.shape == (5000, 32, 32, 3)\n",
    "assert x_test.shape == (5000, 32, 32, 3)\n",
    "\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_val.shape == (5000, 1)\n",
    "assert y_test.shape == (5000, 1)\n",
    "\n",
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir(model_name):\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") + \" \" + model_name\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a817c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = tf.one_hot(np.squeeze(y_train), 100)\n",
    "y_val_onehot = tf.one_hot(np.squeeze(y_val), 100)\n",
    "y_test_onehot = tf.one_hot(np.squeeze(y_test), 100)\n",
    "\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_val = x_val.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8086745e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_onehot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test_onehot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val_onehot))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "42308b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 32, 32, 3) dtype=float32 (created by layer 'input_3')>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for line in train_dataset.take(1):\n",
    "    input_shape = line[0][0].numpy().shape\n",
    "    \n",
    "tf.keras.Input(shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eba0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_16 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "    ], name = \"block_1\"\n",
    ")\n",
    "\n",
    "model_32 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,16)),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "    ], name = \"block_2\"\n",
    ")\n",
    "\n",
    "model_64 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,32)),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name = \"block_3\"\n",
    ")\n",
    "\n",
    "model_16.summary()\n",
    "model_32.summary()\n",
    "model_64.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af1df05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "block_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu')\n",
    "    ], name = \"block_1\"\n",
    ")\n",
    "\n",
    "block_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,256)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "    ], name = \"block_2\"\n",
    ")\n",
    "\n",
    "block_3 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,512)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(7,7), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name = \"block_3\"\n",
    ")\n",
    "\n",
    "block_1.summary()\n",
    "block_2.summary()\n",
    "block_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4127512",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_20_vanilla = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),    \n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8228ca43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mini_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " average_pooling2d_15 (Avera  (None, 1, 1, 16)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 100)               1700      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,148\n",
      "Trainable params: 2,148\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Miniature Model, to be compared to ForcedLearner Small variants\n",
    "\n",
    "mini_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(32,32), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name=\"mini_model\"\n",
    ")\n",
    "\n",
    "mini_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fbf5fe1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5621/2652060014.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Boilerplater model architectures for ForcedLearner Small variants\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m small_1 = tf.keras.Sequential(\n\u001b[0m\u001b[1;32m      4\u001b[0m     [\n\u001b[1;32m      5\u001b[0m         \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "#Boilerplater model architectures for ForcedLearner Small variants\n",
    "\n",
    "small_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "    ], name=\"small_1\"\n",
    ")\n",
    "\n",
    "auxillary = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32,32,3))\n",
    "x = small_1(inputs)\n",
    "outputs = auxillary(x)\n",
    "\n",
    "small_model_pretrain = tf.keras.Model(inputs=inputs, outputs=outputs,name=\"small_model_pretrain\")\n",
    "\n",
    "small_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,32)),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name=\"small_2\"\n",
    ")\n",
    "\n",
    "small_1.summary()\n",
    "smal#Training algorithm and model setup for ForcedLearner Small variants\n",
    "\n",
    "mae_metric_1 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_1 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_2 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_2 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "class ForcedNetSmall(tf.keras.Model):\n",
    "    def __init__(self, block_1, block_2, auxillary):\n",
    "        super(ForcedNetSmall, self).__init__()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(32,32,3))\n",
    "        \n",
    "        self.auxillary_1 = auxillary\n",
    "        \n",
    "        self.model_1 = block_1\n",
    "        \n",
    "        self.model_2 = block_2\n",
    "\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(ForcedNetSmall, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [mae_metric_1, accuracy_metric_1, \n",
    "                mae_metric_2, accuracy_metric_2]\n",
    "        \n",
    "    def call(self, images):\n",
    "        x = self.block_1(images)\n",
    "        x = self.block_2(x)\n",
    "        return self.block_3(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model_1.summary()\n",
    "        self.model_2.summary()\n",
    "        print(\"\\nAuxillary Layers:\")\n",
    "        self.auxillary_1.summary()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:   \n",
    "            x = self.model_1(images)\n",
    "            predictions_1 = self.auxillary_1(x)\n",
    "            \n",
    "            loss_1 = self.loss_fn(labels, predictions_1)\n",
    "        \n",
    "        \n",
    "        #Second model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_2(images)\n",
    "            predictions_2 = self.auxillary_2(x)\n",
    "            \n",
    "            loss_2 = self.loss_fn(labels, predictions_2)\n",
    "            \n",
    "        grads = tape.gradient(loss_2, self.model_2.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_2, self.auxillary_2.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_2.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_2.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        mae_metric_1.update_state(labels, predictions_1)\n",
    "        accuracy_metric_1.update_state(labels, predictions_1) \n",
    "        \n",
    "        mae_metric_2.update_state(labels, predictions_2)\n",
    "        accuracy_metric_2.update_state(labels, predictions_2)\n",
    "        \n",
    "        return {\"Block_1_Loss\": loss_1,\n",
    "                \"Block_2_Loss\": loss_2,\n",
    "                \n",
    "                \"Block_1_MAE\": mae_metric_1.result(),\n",
    "                \"Block_2_MAE\": mae_metric_2.result(), \n",
    "                \n",
    "                \"Block_1_Accuracy\": accuracy_metric_1.result(),\n",
    "                \"Block_2_Accuracy\": accuracy_metric_2.result(), }l_2.summary()\n",
    "mini_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "68e88470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list = [\n",
    "        \n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "]\n",
    "\n",
    "mini_model = [\n",
    "    tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        ], name=\"small_1\"\n",
    "    ), tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.Input(shape=(16,16,32)),\n",
    "            tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        ], name=\"small_2\"\n",
    "    )\n",
    "    \n",
    "]\n",
    "\n",
    "type(mini_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "87f755cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'list'> input: []\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"sequential_29\" (type Sequential).\n\nLayer \"average_pooling2d_28\" expects 1 input(s), but it received 0 input tensors. Inputs received: []\n\nCall arguments received:\n  • inputs=[]\n  • training=None\n  • mask=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5621/524470882.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauxillary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForcedNetSmall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pretrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     model.compile(\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/engine/input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_spec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     raise ValueError(f'Layer \"{layer_name}\" expects {len(input_spec)} input(s),'\n\u001b[0m\u001b[1;32m    200\u001b[0m                      \u001b[0;34mf' but it received {len(inputs)} input tensors. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                      f'Inputs received: {inputs}')\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"sequential_29\" (type Sequential).\n\nLayer \"average_pooling2d_28\" expects 1 input(s), but it received 0 input tensors. Inputs received: []\n\nCall arguments received:\n  • inputs=[]\n  • training=None\n  • mask=None"
     ]
    }
   ],
   "source": [
    "auxillary = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_2_Loss', patience=7)]\n",
    "\n",
    "for i in range(12):\n",
    "    x = tf.keras.Input(shape=(32,32,3))\n",
    "    x = [model_list(x) for _ in range(0, i)]\n",
    "    outputs = auxillary(x)\n",
    "    \n",
    "    model = \n",
    "    \n",
    "    model = ForcedNetSmall(model_pretrain, layer)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "        loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    )\n",
    "    \n",
    "    history = model.fit(train_dataset, epochs=16, callbacks=[callback])\n",
    "    model.pop()\n",
    "    model_pretrain = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478b6bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training algorithm and model setup for ForcedLearner Small variants\n",
    "\n",
    "mae_metric_1 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_1 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "print(\n",
    "mae_metric_2 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_2 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "class ForcedNetSmall(tf.keras.Model):\n",
    "    def __init__(self, block_1, block_2, auxillary):\n",
    "        super(ForcedNetSmall, self).__init__()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(32,32,3))\n",
    "        \n",
    "        self.auxillary_1 = auxillary\n",
    "        \n",
    "        self.model_1 = block_1\n",
    "        \n",
    "        self.model_2 = block_2\n",
    "\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(ForcedNetSmall, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [mae_metric_1, accuracy_metric_1, \n",
    "                mae_metric_2, accuracy_metric_2]\n",
    "        \n",
    "    def call(self, images):\n",
    "        x = self.block_1(images)\n",
    "        x = self.block_2(x)\n",
    "        return self.block_3(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model_1.summary()\n",
    "        self.model_2.summary()\n",
    "        print(\"\\nAuxillary Layers:\")\n",
    "        self.auxillary_1.summary()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "\n",
    "        with tf.GradientTape(persistent=True) as tape:   \n",
    "            x = self.model_1(images)\n",
    "            predictions_1 = self.auxillary_1(x)\n",
    "            \n",
    "            loss_1 = self.loss_fn(labels, predictions_1)\n",
    "        \n",
    "        \n",
    "        #Second model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_2(images)\n",
    "            predictions_2 = self.auxillary_2(x)\n",
    "            \n",
    "            loss_2 = self.loss_fn(labels, predictions_2)\n",
    "            \n",
    "        grads = tape.gradient(loss_2, self.model_2.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_2, self.auxillary_2.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_2.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_2.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        mae_metric_1.update_state(labels, predictions_1)\n",
    "        accuracy_metric_1.update_state(labels, predictions_1) \n",
    "        \n",
    "        mae_metric_2.update_state(labels, predictions_2)\n",
    "        accuracy_metric_2.update_state(labels, predictions_2)\n",
    "        \n",
    "        return {\"Block_1_Loss\": loss_1,\n",
    "                \"Block_2_Loss\": loss_2,\n",
    "                \n",
    "                \"Block_1_MAE\": mae_metric_1.result(),\n",
    "                \"Block_2_MAE\": mae_metric_2.result(), \n",
    "                \n",
    "                \"Block_1_Accuracy\": accuracy_metric_1.result(),\n",
    "                \"Block_2_Accuracy\": accuracy_metric_2.result(), }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7d03bc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-01 21:08:25.174892: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8200\n",
      "2022-01-01 21:08:28.200164: I tensorflow/stream_executor/cuda/cuda_blas.cc:1774] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 8s 6ms/step - loss: 4.4439 - mae: 0.0197 - categorical_accuracy: 0.0190 - lr: 3.0000e-04\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 4.1297 - mae: 0.0195 - categorical_accuracy: 0.0523 - lr: 3.0000e-04\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.9097 - mae: 0.0193 - categorical_accuracy: 0.0854 - lr: 3.0000e-04\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.7294 - mae: 0.0190 - categorical_accuracy: 0.1241 - lr: 3.0000e-04\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.5733 - mae: 0.0187 - categorical_accuracy: 0.1502 - lr: 3.0000e-04\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.4689 - mae: 0.0185 - categorical_accuracy: 0.1731 - lr: 3.0000e-04\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.3722 - mae: 0.0182 - categorical_accuracy: 0.1920 - lr: 3.0000e-04\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.2927 - mae: 0.0181 - categorical_accuracy: 0.2055 - lr: 3.0000e-04\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.2228 - mae: 0.0179 - categorical_accuracy: 0.2203 - lr: 3.0000e-04\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.1663 - mae: 0.0177 - categorical_accuracy: 0.2308 - lr: 3.0000e-04\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.1070 - mae: 0.0175 - categorical_accuracy: 0.2419 - lr: 3.0000e-04\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.0448 - mae: 0.0174 - categorical_accuracy: 0.2533 - lr: 3.0000e-04\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.0008 - mae: 0.0172 - categorical_accuracy: 0.2608 - lr: 3.0000e-04\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.9502 - mae: 0.0171 - categorical_accuracy: 0.2725 - lr: 3.0000e-04\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.9111 - mae: 0.0170 - categorical_accuracy: 0.2789 - lr: 3.0000e-04\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.8603 - mae: 0.0168 - categorical_accuracy: 0.2884 - lr: 3.0000e-04\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.8159 - mae: 0.0167 - categorical_accuracy: 0.2973 - lr: 3.0000e-04\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.7825 - mae: 0.0166 - categorical_accuracy: 0.3051 - lr: 3.0000e-04\n",
      "Epoch 19/200\n",
      " 55/391 [===>..........................] - ETA: 1s - loss: 2.7718 - mae: 0.0166 - categorical_accuracy: 0.2991"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5835/3167754997.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m               optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=metrics)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Model compilation and training for standard \"Mini model\", to be compared to ForcedLearner small\n",
    "\n",
    "run_logdir = get_run_logdir(\"MiniModelVanilla_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "mini_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=metrics)\n",
    "\n",
    "history = mini_model.fit(train_dataset, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0030c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ForcedLearner Small compilation and training\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "run_logdir = get_run_logdir(\"SmallForced_pretrain_Cifar100\")\n",
    "\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7)]\n",
    "small_model_pretrain.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), metrics=[metrics]\n",
    ")\n",
    "\n",
    "history = small_model_pretrain.fit(train_dataset, epochs=125, callbacks=[callback])\n",
    "\n",
    "run_logdir = get_run_logdir(\"SmallForcedLearner_Cifar100\")\n",
    "\n",
    "ForcedSmall = ForcedNetSmall(small_1, small_2, auxillary)\n",
    "\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_2_Loss', patience=7)]\n",
    "ForcedSmall.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "history = ForcedSmall.fit(train_dataset, epochs=75, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c829cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deprecated training for OG ForcedLearning\n",
    "\n",
    "mae_metric_16 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_16 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_32 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_32 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_64 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_64 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "class ForcedNet(tf.keras.Model):\n",
    "    def __init__(self, block_1, block_2, block_3):\n",
    "        super(ForcedNet, self).__init__()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(32,32,3))\n",
    "        \n",
    "        self.auxillary_1 = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.AveragePooling2D(pool_size=(32,32), strides=(1, 1), padding='valid'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.auxillary_2 = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.AveragePooling2D(pool_size=(16,16), strides=(1, 1), padding='valid'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.model_1 = block_1\n",
    "\n",
    "        x = block_1(inputs)\n",
    "        output = block_2(x)\n",
    "        \n",
    "        self.model_2 = tf.keras.Model(inputs=inputs, outputs=output, name=\"section_2\")\n",
    "        \n",
    "        x = self.model_2(inputs)\n",
    "        output = block_3(x)\n",
    "        \n",
    "        self.model_3 = tf.keras.Model(inputs=inputs, outputs = output, name=\"section_3\")\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(ForcedNet, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [mae_metric_16, accuracy_metric_16, \n",
    "                mae_metric_32, accuracy_metric_32, mae_metric_64, accuracy_metric_64]\n",
    "        \n",
    "    def call(self, images):\n",
    "        x = self.block_1(images)\n",
    "        x = self.block_2(x)\n",
    "        return self.block_3(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model_1.summary()\n",
    "        self.model_2.summary()\n",
    "        self.model_3.summary()\n",
    "        print(\"\\nAuxillary Layers:\")\n",
    "        self.auxillary_1.summary()\n",
    "        self.auxillary_2.summary()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        \n",
    "        #First model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_1(images)\n",
    "            predictions_1 = self.auxillary_1(x)\n",
    "            \n",
    "            loss_1 = self.loss_fn(labels, predictions_1)\n",
    "            \n",
    "        grads = tape.gradient(loss_1, self.model_1.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_1, self.auxillary_1.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_1.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_1.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        #Second model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_2(images)\n",
    "            predictions_2 = self.auxillary_2(x)\n",
    "            \n",
    "            loss_2 = self.loss_fn(labels, predictions_2)\n",
    "            \n",
    "        grads = tape.gradient(loss_2, self.model_2.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_2, self.auxillary_2.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_2.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_2.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        #Third model part\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions_3 = self.model_3(images)\n",
    "            \n",
    "            loss_3 = self.loss_fn(labels, predictions_3)\n",
    "            \n",
    "        grads = tape.gradient(loss_3, self.model_3.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_3.trainable_weights,)\n",
    "        )\n",
    "        \n",
    "        mae_metric_16.update_state(labels, predictions_1)\n",
    "        accuracy_metric_16.update_state(labels, predictions_1) \n",
    "        \n",
    "        mae_metric_32.update_state(labels, predictions_2)\n",
    "        accuracy_metric_32.update_state(labels, predictions_2)\n",
    "        \n",
    "        mae_metric_64.update_state(labels, predictions_3)\n",
    "        accuracy_metric_64.update_state(labels, predictions_3)\n",
    "        \n",
    "        return {\"Block_1_Loss\": loss_1, \"Block_2_Loss\": loss_2, \"Block_3_Loss\": loss_3,\n",
    "                \n",
    "                \"Block_1_MAE\": mae_metric_16.result(), \"Block_2_MAE\": mae_metric_32.result(), \n",
    "                \"Block_3_MAE\": mae_metric_64.result(),\n",
    "                \n",
    "                \"Block_1_Accuracy\": accuracy_metric_16.result(), \"Block_2_Accuracy\": accuracy_metric_32.result(), \n",
    "                \"Block_3_Accuracy\": accuracy_metric_64.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd4fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir(\"ForcedLearning20Cifar100Adam\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_3_Loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "ForcedLearner = ForcedNet(block_1, block_2, block_3)\n",
    "ForcedLearner.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "history = ForcedLearner.fit(train_dataset, epochs=50, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21923b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir(\"ForcedLearning20Cifar100Adam_Validation\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_3_Loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "history = ForcedLearner.fit(val_dataset, epochs=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38836b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in val_dataset.take(1):\n",
    "    images = line[0]\n",
    "    predictions = model.predict(line[0])\n",
    "    truth = line[1]\n",
    "\n",
    "labels = []\n",
    "for pred in predictions:\n",
    "    labels.append(np.argmax(pred))\n",
    "\n",
    "truth_labels = []\n",
    "for i in truth:\n",
    "    truth_labels.append(np.argmax(i))\n",
    "\n",
    "num = 13\n",
    "\n",
    "print(labels[num])\n",
    "print(truth_labels[num])\n",
    "\n",
    "#Load image from file\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = images[num].numpy()\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd26a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#inputs = tf.keras.Input(shape=(32,32,3))\n",
    "#x = model_16(inputs)\n",
    "#x = model_32(x)\n",
    "import os\n",
    "\n",
    "vanilla_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(7,7), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name = \"vanilla_model\"\n",
    ")\n",
    "run_logdir = get_run_logdir(\"VanillaModel_Large_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "vanilla_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=metrics)\n",
    "\n",
    "vanilla_model.summary()\n",
    "#history = vanilla_model.fit(train_dataset, epochs=50, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b998e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir(\"DenseNet201_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "model_temp = tf.keras.applications.DenseNet201(weights=None, input_shape=(32,32,3), classes=100)\n",
    "model_temp.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=[metrics])\n",
    "#model_temp.summary()\n",
    "model_temp.fit(train_dataset, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c6213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "344e54fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-fb18d33c299fbe8c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-fb18d33c299fbe8c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-20_07_20 SmallModelVanilla_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5724b891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f06d34bc156fd06\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f06d34bc156fd06\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-20_20_54 SmallForced_pretrain_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90930dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-7fccc16fb0bc888d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-7fccc16fb0bc888d\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-20_25_03 SmallForcedLearner_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bcb211",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
