{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07d128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen from runs prior to run_2021_12_29-00_26_20 ForcedLearning20Cifar100Adam, the categorical\n",
    "#accuracy progresses much more slowly than the vanilla variant of the model. I hypothesize that this is\n",
    "#because the model has to play \"Catch-up\" with itself, because each block is learning independently. This\n",
    "#causes each successive block in the model to spend the next batch adjusting to what the previous batch just\n",
    "#learned, and not gaining any intelligence. I have rectified this by allowing each training step to have the\n",
    "#model pass through one layer, update that specific model_block, pass through another, update that block wrt\n",
    "#the first and second block, and so on. This has increased the time, but vastly increased the speed at which\n",
    "#the model learns, even surpassing the vanilla model at the beginning of the training.\n",
    "\n",
    "#This new forced learning seems to cap out at about 68 percent cat. accuracy, perhaps it is unable to learn\n",
    "#lower features? Perhaps it would fair well with a larger model, and different dataset. I think I should try\n",
    "#creating different optimizers with different learning rates for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c468c651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "x_test, x_val = np.array_split(x_test, 2)\n",
    "y_test, y_val = np.array_split(y_test, 2)\n",
    "\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_val.shape == (5000, 32, 32, 3)\n",
    "assert x_test.shape == (5000, 32, 32, 3)\n",
    "\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_val.shape == (5000, 1)\n",
    "assert y_test.shape == (5000, 1)\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir(model_name):\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") + \" \" + model_name\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e368ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_onehot = tf.one_hot(np.squeeze(y_train), 100)\n",
    "y_val_onehot = tf.one_hot(np.squeeze(y_val), 100)\n",
    "y_test_onehot = tf.one_hot(np.squeeze(y_test), 100)\n",
    "\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_val = x_val.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_onehot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test_onehot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val_onehot))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c91acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "small_1 = tf.keras.Sequential(\n",
    "        [\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "            tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "auxillary = tf.keras.Sequential(\n",
    "        [\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "        ]\n",
    "    )\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32,32,3))\n",
    "x = small_1(inputs)\n",
    "outputs = auxillary(x)\n",
    "\n",
    "small_model_pretrain = tf.keras.Model(inputs=inputs, outputs=outputs,name=\"small_model_pretrain\")\n",
    "\n",
    "small_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,32)),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e65c0a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_metric_1 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_1 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_2 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_2 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "class ForcedNetSmall(tf.keras.Model):\n",
    "    def __init__(self, block_1, block_2, auxillary):\n",
    "        super(ForcedNetSmall, self).__init__()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(32,32,3))\n",
    "        \n",
    "        self.auxillary_1 = auxillary\n",
    "        \n",
    "        self.model_1 = block_1\n",
    "        \n",
    "        self.model_2 = block_2\n",
    "\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(ForcedNetSmall, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [mae_metric_1, accuracy_metric_1, \n",
    "                mae_metric_2, accuracy_metric_2]\n",
    "        \n",
    "    def call(self, images):\n",
    "        x = self.block_1(images)\n",
    "        x = self.block_2(x)\n",
    "        return self.block_3(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model_1.summary()\n",
    "        self.model_2.summary()\n",
    "        print(\"\\nAuxillary Layers:\")\n",
    "        self.auxillary_1.summary()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        x = self.model_1(images)\n",
    "        predictions_1 = self.auxillary_1(x)\n",
    "        \n",
    "        \n",
    "        #Second model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_2(images)\n",
    "            predictions_2 = self.auxillary_2(x)\n",
    "            \n",
    "            loss_2 = self.loss_fn(labels, predictions_2)\n",
    "            \n",
    "        grads = tape.gradient(loss_2, self.model_2.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_2, self.auxillary_2.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_2.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_2.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        mae_metric_1.update_state(labels, predictions_1)\n",
    "        accuracy_metric_1.update_state(labels, predictions_1) \n",
    "        \n",
    "        mae_metric_2.update_state(labels, predictions_2)\n",
    "        accuracy_metric_2.update_state(labels, predictions_2)\n",
    "        \n",
    "        return {\"Block_1_Loss\": loss_1,\n",
    "                \"Block_2_Loss\": loss_2,\n",
    "                \n",
    "                \"Block_1_MAE\": mae_metric_1.result(),\n",
    "                \"Block_2_MAE\": mae_metric_2.result(), \n",
    "                \n",
    "                \"Block_1_Accuracy\": accuracy_metric_1.result(),\n",
    "                \"Block_2_Accuracy\": accuracy_metric_2.result(), }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir(\"SmallModelVanilla_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "mini_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=metrics)\n",
    "\n",
    "history = mini_model.fit(train_dataset, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c7b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "run_logdir = get_run_logdir(\"SmallForced_pretrain_Cifar100\")\n",
    "\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "small_model_pretrain.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), metrics=[metrics]\n",
    ")\n",
    "\n",
    "history = small_model_pretrain.fit(train_dataset, epochs=125, callbacks=[callback])\n",
    "\n",
    "run_logdir = get_run_logdir(\"SmallForcedLearner_Cifar100\")\n",
    "\n",
    "ForcedSmall = ForcedNetSmall(small_1, small_2, auxillary)\n",
    "\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_2_Loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "ForcedSmall.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "history = ForcedSmall.fit(train_dataset, epochs=75, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0c4224d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-24a01771fd10cf65\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-24a01771fd10cf65\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6009;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-20_07_20 SmallModelVanilla_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d55bfb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 49115), started 0:00:50 ago. (Use '!kill 49115' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6244800c10ffa667\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6244800c10ffa667\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-20_20_54 SmallForced_pretrain_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c0e0a94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 49207), started 0:00:49 ago. (Use '!kill 49207' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-861b942ee112516c\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-861b942ee112516c\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-20_25_03 SmallForcedLearner_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d52286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
