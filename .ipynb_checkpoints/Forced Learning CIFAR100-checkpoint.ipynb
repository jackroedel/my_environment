{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052125fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As can be seen from runs prior to run_2021_12_29-00_26_20 ForcedLearning20Cifar100Adam, the categorical\n",
    "#accuracy progresses much more slowly than the vanilla variant of the model. I hypothesize that this is\n",
    "#because the model has to play \"Catch-up\" with itself, because each block is learning independently. This\n",
    "#causes each successive block in the model to spend the next batch adjusting to what the previous batch just\n",
    "#learned, and not gaining any intelligence. I have rectified this by allowing each training step to have the\n",
    "#model pass through one layer, update that specific model_block, pass through another, update that block wrt\n",
    "#the first and second block, and so on. This has increased the time, but vastly increased the speed at which\n",
    "#the model learns, even surpassing the vanilla model at the beginning of the training.\n",
    "\n",
    "#This new forced learning seems to cap out at about 68 percent cat. accuracy, perhaps it is unable to learn\n",
    "#lower features? Perhaps it would fair well with a larger model, and different dataset. I think I should try\n",
    "#creating different optimizers with different learning rates for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22bf7635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar100.load_data()\n",
    "\n",
    "x_test, x_val = np.array_split(x_test, 2)\n",
    "y_test, y_val = np.array_split(y_test, 2)\n",
    "\n",
    "assert x_train.shape == (50000, 32, 32, 3)\n",
    "assert x_val.shape == (5000, 32, 32, 3)\n",
    "assert x_test.shape == (5000, 32, 32, 3)\n",
    "\n",
    "assert y_train.shape == (50000, 1)\n",
    "assert y_val.shape == (5000, 1)\n",
    "assert y_test.shape == (5000, 1)\n",
    "\n",
    "import os\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "def get_run_logdir(model_name):\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\") + \" \" + model_name\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a817c0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-29 19:29:27.365791: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.371499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.371687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.396229: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-29 19:29:27.399127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.399582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.399960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.682973: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.683122: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.683240: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-29 19:29:27.683350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7936 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "y_train_onehot = tf.one_hot(np.squeeze(y_train), 100)\n",
    "y_val_onehot = tf.one_hot(np.squeeze(y_val), 100)\n",
    "y_test_onehot = tf.one_hot(np.squeeze(y_test), 100)\n",
    "\n",
    "x_train = x_train.astype(\"float32\")/255\n",
    "x_val = x_val.astype(\"float32\")/255\n",
    "x_test = x_test.astype(\"float32\")/255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8086745e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_onehot))\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test_onehot))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val_onehot))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)\n",
    "val_dataset = val_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)\n",
    "test_dataset = test_dataset.shuffle(buffer_size=1024).batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "42308b14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TakeDataset shapes: ((None, 32, 32, 3), (None, 100)), types: (tf.float32, tf.float32)>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "01eba0a6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"block_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_231 (Conv2D)         (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " conv2d_232 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_233 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_234 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_235 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_236 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_237 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,368\n",
      "Trainable params: 14,368\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"block_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_238 (Conv2D)         (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_239 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_240 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 60,128\n",
      "Trainable params: 60,128\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"block_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_245 (Conv2D)         (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_246 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_247 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_248 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_249 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_250 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_251 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " average_pooling2d_59 (Avera  (None, 1, 1, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_59 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 246,564\n",
      "Trainable params: 246,564\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_16 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "    ], name = \"block_1\"\n",
    ")\n",
    "\n",
    "model_32 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,16)),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "    ], name = \"block_2\"\n",
    ")\n",
    "\n",
    "model_64 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,32)),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name = \"block_3\"\n",
    ")\n",
    "\n",
    "model_16.summary()\n",
    "model_32.summary()\n",
    "model_64.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1af1df05",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"block_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_112 (Conv2D)         (None, 32, 32, 64)        256       \n",
      "                                                                 \n",
      " conv2d_113 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_114 (Conv2D)         (None, 32, 32, 256)       16640     \n",
      "                                                                 \n",
      " conv2d_115 (Conv2D)         (None, 32, 32, 64)        16448     \n",
      "                                                                 \n",
      " conv2d_116 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_117 (Conv2D)         (None, 32, 32, 256)       16640     \n",
      "                                                                 \n",
      " conv2d_118 (Conv2D)         (None, 32, 32, 64)        16448     \n",
      "                                                                 \n",
      " conv2d_119 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_120 (Conv2D)         (None, 32, 32, 256)       16640     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 193,856\n",
      "Trainable params: 193,856\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"block_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling2d_6 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_121 (Conv2D)         (None, 16, 16, 128)       32896     \n",
      "                                                                 \n",
      " conv2d_122 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_123 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " conv2d_124 (Conv2D)         (None, 16, 16, 128)       65664     \n",
      "                                                                 \n",
      " conv2d_125 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_126 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " conv2d_127 (Conv2D)         (None, 16, 16, 128)       65664     \n",
      "                                                                 \n",
      " conv2d_128 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_129 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " conv2d_130 (Conv2D)         (None, 16, 16, 128)       65664     \n",
      "                                                                 \n",
      " conv2d_131 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_132 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,084,416\n",
      "Trainable params: 1,084,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"block_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " max_pooling2d_7 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_133 (Conv2D)         (None, 8, 8, 512)         262656    \n",
      "                                                                 \n",
      " conv2d_134 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_135 (Conv2D)         (None, 8, 8, 2048)        1050624   \n",
      "                                                                 \n",
      " conv2d_136 (Conv2D)         (None, 8, 8, 512)         1049088   \n",
      "                                                                 \n",
      " conv2d_137 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_138 (Conv2D)         (None, 8, 8, 2048)        1050624   \n",
      "                                                                 \n",
      " conv2d_139 (Conv2D)         (None, 8, 8, 512)         1049088   \n",
      "                                                                 \n",
      " conv2d_140 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_141 (Conv2D)         (None, 8, 8, 2048)        1050624   \n",
      "                                                                 \n",
      " average_pooling2d_11 (Avera  (None, 2, 2, 2048)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 100)               819300    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,411,428\n",
      "Trainable params: 13,411,428\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "block_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu')\n",
    "    ], name = \"block_1\"\n",
    ")\n",
    "\n",
    "block_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,256)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "    ], name = \"block_2\"\n",
    ")\n",
    "\n",
    "block_3 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,512)),\n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(7,7), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name = \"block_3\"\n",
    ")\n",
    "\n",
    "block_1.summary()\n",
    "block_2.summary()\n",
    "block_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0fee0120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_172 (Conv2D)         (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " conv2d_173 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_174 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_175 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_176 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_177 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_178 (Conv2D)         (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_179 (Conv2D)         (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_180 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_181 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_182 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_183 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_184 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_185 (Conv2D)         (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " input_15 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " conv2d_186 (Conv2D)         (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_187 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_188 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_189 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_190 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_191 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_192 (Conv2D)         (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " average_pooling2d_15 (Avera  (None, 1, 1, 64)         0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 100)               6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 321,060\n",
      "Trainable params: 321,060\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_20_vanilla = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),    \n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87c63327",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_44 (Conv2D)          (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 32, 32, 16)        2320      \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 16, 16, 32)        4640      \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_50 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 16, 16, 32)        9248      \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 8, 8, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " conv2d_55 (Conv2D)          (None, 8, 8, 64)          36928     \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 1, 1, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 100)               6500      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,572\n",
      "Trainable params: 175,572\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mini_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "mini_model.summary()\n",
    "\n",
    "small_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(16, 3, padding='same',activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(32, 3, padding=\"same\", activation='relu'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "auxillary = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "inputs = tf.keras.Input(shape=(32,32,3))\n",
    "x = small_1(inputs)\n",
    "outputs = auxillary(x)\n",
    "\n",
    "small_model_pretrain = tf.keras.Model(inputs=inputs, outputs=outputs,name=\"small_model_pretrain\")\n",
    "\n",
    "small_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(16,16,32)),\n",
    "        tf.keras.layers.Conv2D(64, 3, strides=(2,2), padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0cf5fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_metric_1 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_1 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_2 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_2 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "class ForcedNetSmall(tf.keras.Model):\n",
    "    def __init__(self, block_1, block_2):\n",
    "        super(ForcedNetSmall, self).__init__()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(32,32,3))\n",
    "        \n",
    "        self.auxillary_1 = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.AveragePooling2D(pool_size=(8,8), strides=(1, 1), padding='valid'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.model_1 = block_1\n",
    "        \n",
    "        self.model_2 = block_2\n",
    "\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(ForcedNetSmall, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [mae_metric_1, accuracy_metric_1, \n",
    "                mae_metric_2, accuracy_metric_2]\n",
    "        \n",
    "    def call(self, images):\n",
    "        x = self.block_1(images)\n",
    "        x = self.block_2(x)\n",
    "        return self.block_3(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model_1.summary()\n",
    "        self.model_2.summary()\n",
    "        print(\"\\nAuxillary Layers:\")\n",
    "        self.auxillary_1.summary()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        \n",
    "        x = self.model_1(images)\n",
    "        predictions_1 = self.auxillary_1(x)\n",
    "        \n",
    "        loss_1 = self.loss_fn(labels, predictions_1)\n",
    "        \n",
    "        #Second model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_1(images)\n",
    "            predictions_2 = self.model_2(x)\n",
    "            \n",
    "            loss_2 = self.loss_fn(labels, predictions_2)\n",
    "            \n",
    "        grads = tape.gradient(loss_2, self.model_2.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_2.trainable_weights,)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        mae_metric_1.update_state(labels, predictions_1)\n",
    "        accuracy_metric_1.update_state(labels, predictions_1) \n",
    "        \n",
    "        mae_metric_2.update_state(labels, predictions_2)\n",
    "        accuracy_metric_2.update_state(labels, predictions_2)\n",
    "        \n",
    "        return {\"Block_1_Loss\": loss_1,\n",
    "                \"Block_2_Loss\": loss_2,\n",
    "                \n",
    "                \"Block_1_MAE\": mae_metric_1.result(),\n",
    "                \"Block_2_MAE\": mae_metric_2.result(), \n",
    "                \n",
    "                \"Block_1_Accuracy\": accuracy_metric_1.result(),\n",
    "                \"Block_2_Accuracy\": accuracy_metric_2.result(), }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc4587",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 4.4496 - mae: 0.0197 - categorical_accuracy: 0.0188 - lr: 3.0000e-04\n",
      "Epoch 2/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 4.1617 - mae: 0.0195 - categorical_accuracy: 0.0479 - lr: 3.0000e-04\n",
      "Epoch 3/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.8876 - mae: 0.0192 - categorical_accuracy: 0.0888 - lr: 3.0000e-04\n",
      "Epoch 4/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.7317 - mae: 0.0190 - categorical_accuracy: 0.1179 - lr: 3.0000e-04\n",
      "Epoch 5/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.6026 - mae: 0.0188 - categorical_accuracy: 0.1427 - lr: 3.0000e-04\n",
      "Epoch 6/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.5017 - mae: 0.0186 - categorical_accuracy: 0.1621 - lr: 3.0000e-04\n",
      "Epoch 7/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.4031 - mae: 0.0183 - categorical_accuracy: 0.1790 - lr: 3.0000e-04\n",
      "Epoch 8/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.3244 - mae: 0.0182 - categorical_accuracy: 0.1942 - lr: 3.0000e-04\n",
      "Epoch 9/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.2552 - mae: 0.0180 - categorical_accuracy: 0.2061 - lr: 3.0000e-04\n",
      "Epoch 10/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.1842 - mae: 0.0178 - categorical_accuracy: 0.2231 - lr: 3.0000e-04\n",
      "Epoch 11/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.1192 - mae: 0.0176 - categorical_accuracy: 0.2353 - lr: 3.0000e-04\n",
      "Epoch 12/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.0640 - mae: 0.0175 - categorical_accuracy: 0.2459 - lr: 3.0000e-04\n",
      "Epoch 13/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 3.0103 - mae: 0.0173 - categorical_accuracy: 0.2578 - lr: 3.0000e-04\n",
      "Epoch 14/200\n",
      "391/391 [==============================] - 3s 6ms/step - loss: 2.9584 - mae: 0.0172 - categorical_accuracy: 0.2688 - lr: 3.0000e-04\n",
      "Epoch 15/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.9110 - mae: 0.0170 - categorical_accuracy: 0.2769 - lr: 3.0000e-04\n",
      "Epoch 16/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.8654 - mae: 0.0169 - categorical_accuracy: 0.2853 - lr: 3.0000e-04\n",
      "Epoch 17/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.8294 - mae: 0.0167 - categorical_accuracy: 0.2931 - lr: 3.0000e-04\n",
      "Epoch 18/200\n",
      "391/391 [==============================] - 3s 7ms/step - loss: 2.7882 - mae: 0.0166 - categorical_accuracy: 0.3018 - lr: 3.0000e-04\n",
      "Epoch 19/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.7436 - mae: 0.0165 - categorical_accuracy: 0.3103 - lr: 3.0000e-04\n",
      "Epoch 20/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.7079 - mae: 0.0163 - categorical_accuracy: 0.3189 - lr: 3.0000e-04\n",
      "Epoch 21/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.6726 - mae: 0.0162 - categorical_accuracy: 0.3272 - lr: 3.0000e-04\n",
      "Epoch 22/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.6341 - mae: 0.0161 - categorical_accuracy: 0.3349 - lr: 3.0000e-04\n",
      "Epoch 23/200\n",
      "391/391 [==============================] - 2s 6ms/step - loss: 2.5894 - mae: 0.0159 - categorical_accuracy: 0.3440 - lr: 3.0000e-04\n",
      "Epoch 24/200\n",
      "229/391 [================>.............] - ETA: 0s - loss: 2.5686 - mae: 0.0158 - categorical_accuracy: 0.3453"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir(\"MiniModel8_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "mini_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=metrics)\n",
    "\n",
    "history = mini_model.fit(train_dataset, epochs=200, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "09125d39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36406/438709224.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmini_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2860\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2861\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2862\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2863\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2864\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "history = mini_model.fit(val_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bdbf7109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "391/391 [==============================] - 2s 5ms/step - loss: 0.7660 - mae: 0.0063 - categorical_accuracy: 0.7639 - lr: 0.0030\n",
      "Epoch 2/125\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7538 - mae: 0.0062 - categorical_accuracy: 0.7653 - lr: 0.0030\n",
      "Epoch 3/125\n",
      "391/391 [==============================] - 2s 4ms/step - loss: 0.7327 - mae: 0.0061 - categorical_accuracy: 0.7726 - lr: 0.0030\n",
      "Epoch 4/125\n",
      "193/391 [=============>................] - ETA: 0s - loss: 0.7501 - mae: 0.0061 - categorical_accuracy: 0.7693"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36406/4121951113.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall_model_pretrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m125\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "run_logdir = get_run_logdir(\"SmallForced_pretrain_Cifar100\")\n",
    "\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "small_model_pretrain.compile(\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003), metrics=[metrics]\n",
    ")\n",
    "\n",
    "history = small_model_pretrain.fit(train_dataset, epochs=125, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ac4ffd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 4.1018 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0196 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.0304 - lr: 0.0030\n",
      "Epoch 2/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 3.3282 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0184 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.1577 - lr: 0.0030\n",
      "Epoch 3/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 2.9655 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0174 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.2328 - lr: 0.0030\n",
      "Epoch 4/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 2.7490 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0167 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.2819 - lr: 0.0030\n",
      "Epoch 5/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 2.5933 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0161 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.3184 - lr: 0.0030\n",
      "Epoch 6/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 2.4616 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0156 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.3432 - lr: 0.0030\n",
      "Epoch 7/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6863 - Block_2_Loss: 2.3382 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0152 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.3709 - lr: 0.0030\n",
      "Epoch 8/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6863 - Block_2_Loss: 2.2238 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0147 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.3971 - lr: 0.0030\n",
      "Epoch 9/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 2.1228 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0143 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.4184 - lr: 0.0030\n",
      "Epoch 10/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 2.0286 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0139 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.4423 - lr: 0.0030\n",
      "Epoch 11/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 1.9291 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0134 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.4589 - lr: 0.0030\n",
      "Epoch 12/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.8423 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0130 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.4854 - lr: 0.0030\n",
      "Epoch 13/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6864 - Block_2_Loss: 1.7521 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0126 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.5000 - lr: 0.0030\n",
      "Epoch 14/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.6681 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0121 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.5240 - lr: 0.0030\n",
      "Epoch 15/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6865 - Block_2_Loss: 1.5940 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0118 - Block_1_Accuracy: 0.0094 - Block_2_Accuracy: 0.5409 - lr: 0.0030\n",
      "Epoch 16/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 1.5171 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0114 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.5573 - lr: 0.0030\n",
      "Epoch 17/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.4549 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0111 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.5742 - lr: 0.0030\n",
      "Epoch 18/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.3957 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0107 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.5865 - lr: 0.0030\n",
      "Epoch 19/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 1.3404 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0104 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.5962 - lr: 0.0030\n",
      "Epoch 20/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 1.2872 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0101 - Block_1_Accuracy: 0.0094 - Block_2_Accuracy: 0.6134 - lr: 0.0030\n",
      "Epoch 21/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6864 - Block_2_Loss: 1.2376 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0098 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.6277 - lr: 0.0030\n",
      "Epoch 22/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6859 - Block_2_Loss: 1.1985 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0096 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.6344 - lr: 0.0030\n",
      "Epoch 23/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.1802 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0094 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.6395 - lr: 0.0030\n",
      "Epoch 24/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 1.1170 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0090 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.6605 - lr: 0.0030\n",
      "Epoch 25/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6864 - Block_2_Loss: 1.0841 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0088 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.6717 - lr: 0.0030\n",
      "Epoch 26/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.0619 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0086 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.6718 - lr: 0.0030\n",
      "Epoch 27/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 1.0239 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0084 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.6818 - lr: 0.0030\n",
      "Epoch 28/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.9952 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0083 - Block_1_Accuracy: 0.0094 - Block_2_Accuracy: 0.6866 - lr: 0.0030\n",
      "Epoch 29/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.9833 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0080 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.6934 - lr: 0.0030\n",
      "Epoch 30/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6859 - Block_2_Loss: 0.9416 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0079 - Block_1_Accuracy: 0.0090 - Block_2_Accuracy: 0.7014 - lr: 0.0030\n",
      "Epoch 31/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6865 - Block_2_Loss: 0.9175 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0077 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7095 - lr: 0.0030\n",
      "Epoch 32/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.8969 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0074 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.7187 - lr: 0.0030\n",
      "Epoch 33/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6863 - Block_2_Loss: 0.8964 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0074 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7154 - lr: 0.0030\n",
      "Epoch 34/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6859 - Block_2_Loss: 0.8819 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0074 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7187 - lr: 0.0030\n",
      "Epoch 35/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.8484 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0071 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7308 - lr: 0.0030\n",
      "Epoch 36/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.8388 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0069 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.7343 - lr: 0.0030\n",
      "Epoch 37/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6858 - Block_2_Loss: 0.8171 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0068 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.7410 - lr: 0.0030\n",
      "Epoch 38/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.8037 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0067 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.7412 - lr: 0.0030\n",
      "Epoch 39/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.7860 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0066 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7473 - lr: 0.0030\n",
      "Epoch 40/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.7839 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0065 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7529 - lr: 0.0030\n",
      "Epoch 41/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6859 - Block_2_Loss: 0.7906 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0066 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.7428 - lr: 0.0030\n",
      "Epoch 42/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.7643 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0063 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7544 - lr: 0.0030\n",
      "Epoch 43/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.7525 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0063 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7542 - lr: 0.0030\n",
      "Epoch 44/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.7450 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0063 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7519 - lr: 0.0030\n",
      "Epoch 45/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.7455 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0060 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7641 - lr: 0.0030\n",
      "Epoch 46/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.7272 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0060 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7647 - lr: 0.0030\n",
      "Epoch 47/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.7100 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0059 - Block_1_Accuracy: 0.0094 - Block_2_Accuracy: 0.7703 - lr: 0.0030\n",
      "Epoch 48/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6864 - Block_2_Loss: 0.7008 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0058 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.7762 - lr: 0.0030\n",
      "Epoch 49/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.6966 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0058 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7765 - lr: 0.0030\n",
      "Epoch 50/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.6951 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0057 - Block_1_Accuracy: 0.0094 - Block_2_Accuracy: 0.7771 - lr: 0.0030\n",
      "Epoch 51/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6859 - Block_2_Loss: 0.7084 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0058 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.7722 - lr: 0.0030\n",
      "Epoch 52/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.6935 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0056 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7798 - lr: 0.0030\n",
      "Epoch 53/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.6737 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0056 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.7804 - lr: 0.0030\n",
      "Epoch 54/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.6834 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0055 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7839 - lr: 0.0030\n",
      "Epoch 55/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.6942 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0056 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7769 - lr: 0.0030\n",
      "Epoch 56/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.6540 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0054 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7870 - lr: 0.0030\n",
      "Epoch 57/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6863 - Block_2_Loss: 0.5323 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0053 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.7865 - lr: 3.0000e-04\n",
      "Epoch 58/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6859 - Block_2_Loss: 0.3252 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0039 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.8661 - lr: 3.0000e-04\n",
      "Epoch 59/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.2416 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0032 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9111 - lr: 3.0000e-04\n",
      "Epoch 60/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.1919 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0027 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9399 - lr: 3.0000e-04\n",
      "Epoch 61/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6861 - Block_2_Loss: 0.1586 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0023 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9571 - lr: 3.0000e-04\n",
      "Epoch 62/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.1330 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0020 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9692 - lr: 3.0000e-04\n",
      "Epoch 63/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6865 - Block_2_Loss: 0.1129 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0018 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9783 - lr: 3.0000e-04\n",
      "Epoch 64/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6863 - Block_2_Loss: 0.0967 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0016 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9844 - lr: 3.0000e-04\n",
      "Epoch 65/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.0829 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0014 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9888 - lr: 3.0000e-04\n",
      "Epoch 66/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.0716 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0012 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9920 - lr: 3.0000e-04\n",
      "Epoch 67/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.0616 - Block_1_MAE: 0.0198 - Block_2_MAE: 0.0011 - Block_1_Accuracy: 0.0094 - Block_2_Accuracy: 0.9948 - lr: 3.0000e-04\n",
      "Epoch 68/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.0532 - Block_1_MAE: 0.0198 - Block_2_MAE: 9.4986e-04 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9960 - lr: 3.0000e-04\n",
      "Epoch 69/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.0461 - Block_1_MAE: 0.0198 - Block_2_MAE: 8.3878e-04 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9972 - lr: 3.0000e-04\n",
      "Epoch 70/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.0399 - Block_1_MAE: 0.0198 - Block_2_MAE: 7.3953e-04 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9981 - lr: 3.0000e-04\n",
      "Epoch 71/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6863 - Block_2_Loss: 0.0346 - Block_1_MAE: 0.0198 - Block_2_MAE: 6.5436e-04 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.9986 - lr: 3.0000e-04\n",
      "Epoch 72/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.0300 - Block_1_MAE: 0.0198 - Block_2_MAE: 5.7310e-04 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9989 - lr: 3.0000e-04\n",
      "Epoch 73/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.0261 - Block_1_MAE: 0.0198 - Block_2_MAE: 5.0300e-04 - Block_1_Accuracy: 0.0093 - Block_2_Accuracy: 0.9991 - lr: 3.0000e-04\n",
      "Epoch 74/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6862 - Block_2_Loss: 0.0229 - Block_1_MAE: 0.0198 - Block_2_MAE: 4.4509e-04 - Block_1_Accuracy: 0.0092 - Block_2_Accuracy: 0.9993 - lr: 3.0000e-04\n",
      "Epoch 75/75\n",
      "391/391 [==============================] - 2s 5ms/step - Block_1_Loss: 4.6860 - Block_2_Loss: 0.0201 - Block_1_MAE: 0.0198 - Block_2_MAE: 3.9308e-04 - Block_1_Accuracy: 0.0091 - Block_2_Accuracy: 0.9996 - lr: 3.0000e-04\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir(\"SmallForcedLearner_Cifar100\")\n",
    "\n",
    "ForcedSmall = ForcedNetSmall(small_1, small_2)\n",
    "\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_2_Loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "ForcedSmall.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "history = ForcedSmall.fit(train_dataset, epochs=75, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c829cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mae_metric_16 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_16 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_32 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_32 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "mae_metric_64 = tf.keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "accuracy_metric_64 = tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")\n",
    "\n",
    "class ForcedNet(tf.keras.Model):\n",
    "    def __init__(self, block_1, block_2, block_3):\n",
    "        super(ForcedNet, self).__init__()\n",
    "        \n",
    "        inputs = tf.keras.Input(shape=(32,32,3))\n",
    "        \n",
    "        self.auxillary_1 = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.AveragePooling2D(pool_size=(32,32), strides=(1, 1), padding='valid'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.auxillary_2 = tf.keras.Sequential(\n",
    "            [\n",
    "                tf.keras.layers.AveragePooling2D(pool_size=(16,16), strides=(1, 1), padding='valid'),\n",
    "                tf.keras.layers.Flatten(),\n",
    "                tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        self.model_1 = block_1\n",
    "\n",
    "        x = block_1(inputs)\n",
    "        output = block_2(x)\n",
    "        \n",
    "        self.model_2 = tf.keras.Model(inputs=inputs, outputs=output, name=\"section_2\")\n",
    "        \n",
    "        x = self.model_2(inputs)\n",
    "        output = block_3(x)\n",
    "        \n",
    "        self.model_3 = tf.keras.Model(inputs=inputs, outputs = output, name=\"section_3\")\n",
    "        \n",
    "    def compile(self, optimizer, loss_fn):\n",
    "        super(ForcedNet, self).compile()\n",
    "        self.optimizer = optimizer\n",
    "        self.loss_fn = loss_fn\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [mae_metric_16, accuracy_metric_16, \n",
    "                mae_metric_32, accuracy_metric_32, mae_metric_64, accuracy_metric_64]\n",
    "        \n",
    "    def call(self, images):\n",
    "        x = self.block_1(images)\n",
    "        x = self.block_2(x)\n",
    "        return self.block_3(x)\n",
    "    \n",
    "    def summary(self):\n",
    "        self.model_1.summary()\n",
    "        self.model_2.summary()\n",
    "        self.model_3.summary()\n",
    "        print(\"\\nAuxillary Layers:\")\n",
    "        self.auxillary_1.summary()\n",
    "        self.auxillary_2.summary()\n",
    "        \n",
    "    def train_step(self, data):\n",
    "        images = data[0]\n",
    "        labels = data[1]\n",
    "        \n",
    "        #First model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_1(images)\n",
    "            predictions_1 = self.auxillary_1(x)\n",
    "            \n",
    "            loss_1 = self.loss_fn(labels, predictions_1)\n",
    "            \n",
    "        grads = tape.gradient(loss_1, self.model_1.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_1, self.auxillary_1.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_1.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_1.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        #Second model part\n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            x = self.model_2(images)\n",
    "            predictions_2 = self.auxillary_2(x)\n",
    "            \n",
    "            loss_2 = self.loss_fn(labels, predictions_2)\n",
    "            \n",
    "        grads = tape.gradient(loss_2, self.model_2.trainable_weights)\n",
    "        grads_output = tape.gradient(loss_2, self.auxillary_2.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_2.trainable_weights,)\n",
    "        )\n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads_output, self.auxillary_2.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        #Third model part\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions_3 = self.model_3(images)\n",
    "            \n",
    "            loss_3 = self.loss_fn(labels, predictions_3)\n",
    "            \n",
    "        grads = tape.gradient(loss_3, self.model_3.trainable_weights)\n",
    "        \n",
    "        self.optimizer.apply_gradients(\n",
    "            zip(grads, self.model_3.trainable_weights,)\n",
    "        )\n",
    "        \n",
    "        mae_metric_16.update_state(labels, predictions_1)\n",
    "        accuracy_metric_16.update_state(labels, predictions_1) \n",
    "        \n",
    "        mae_metric_32.update_state(labels, predictions_2)\n",
    "        accuracy_metric_32.update_state(labels, predictions_2)\n",
    "        \n",
    "        mae_metric_64.update_state(labels, predictions_3)\n",
    "        accuracy_metric_64.update_state(labels, predictions_3)\n",
    "        \n",
    "        return {\"Block_1_Loss\": loss_1, \"Block_2_Loss\": loss_2, \"Block_3_Loss\": loss_3,\n",
    "                \n",
    "                \"Block_1_MAE\": mae_metric_16.result(), \"Block_2_MAE\": mae_metric_32.result(), \n",
    "                \"Block_3_MAE\": mae_metric_64.result(),\n",
    "                \n",
    "                \"Block_1_Accuracy\": accuracy_metric_16.result(), \"Block_2_Accuracy\": accuracy_metric_32.result(), \n",
    "                \"Block_3_Accuracy\": accuracy_metric_64.result()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08dd4fc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_logdir = get_run_logdir(\"ForcedLearning20Cifar100Adam\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_3_Loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "ForcedLearner = ForcedNet(block_1, block_2, block_3)\n",
    "ForcedLearner.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.003),\n",
    "    loss_fn=tf.keras.losses.CategoricalCrossentropy(),\n",
    ")\n",
    "\n",
    "history = ForcedLearner.fit(train_dataset, epochs=50, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "21923b34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 6s 155ms/step - Block_1_Loss: 2.4952 - Block_2_Loss: 0.6355 - Block_3_Loss: 0.0084 - Block_1_MAE: 0.0158 - Block_2_MAE: 0.0065 - Block_3_MAE: 7.9498e-05 - Block_1_Accuracy: 0.3490 - Block_2_Accuracy: 0.7849 - Block_3_Accuracy: 0.9994 - lr: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir(\"ForcedLearning20Cifar100Adam_Validation\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='Block_3_Loss', patience=7), tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "history = ForcedLearner.fit(val_dataset, epochs=1, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "38836b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "84\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for line in val_dataset.take(1):\n",
    "    images = line[0]\n",
    "    predictions = model.predict(line[0])\n",
    "    truth = line[1]\n",
    "\n",
    "labels = []\n",
    "for pred in predictions:\n",
    "    labels.append(np.argmax(pred))\n",
    "\n",
    "truth_labels = []\n",
    "for i in truth:\n",
    "    truth_labels.append(np.argmax(i))\n",
    "\n",
    "num = 13\n",
    "\n",
    "print(labels[num])\n",
    "print(truth_labels[num])\n",
    "\n",
    "#Load image from file\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "img = images[num].numpy()\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd26a11",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vanilla_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_142 (Conv2D)         (None, 32, 32, 64)        256       \n",
      "                                                                 \n",
      " conv2d_143 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_144 (Conv2D)         (None, 32, 32, 256)       16640     \n",
      "                                                                 \n",
      " conv2d_145 (Conv2D)         (None, 32, 32, 64)        16448     \n",
      "                                                                 \n",
      " conv2d_146 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_147 (Conv2D)         (None, 32, 32, 256)       16640     \n",
      "                                                                 \n",
      " conv2d_148 (Conv2D)         (None, 32, 32, 64)        16448     \n",
      "                                                                 \n",
      " conv2d_149 (Conv2D)         (None, 32, 32, 64)        36928     \n",
      "                                                                 \n",
      " conv2d_150 (Conv2D)         (None, 32, 32, 256)       16640     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 16, 16, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_151 (Conv2D)         (None, 16, 16, 128)       32896     \n",
      "                                                                 \n",
      " conv2d_152 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_153 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " conv2d_154 (Conv2D)         (None, 16, 16, 128)       65664     \n",
      "                                                                 \n",
      " conv2d_155 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_156 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " conv2d_157 (Conv2D)         (None, 16, 16, 128)       65664     \n",
      "                                                                 \n",
      " conv2d_158 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_159 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " conv2d_160 (Conv2D)         (None, 16, 16, 128)       65664     \n",
      "                                                                 \n",
      " conv2d_161 (Conv2D)         (None, 16, 16, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_162 (Conv2D)         (None, 16, 16, 512)       66048     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 8, 8, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_163 (Conv2D)         (None, 8, 8, 512)         262656    \n",
      "                                                                 \n",
      " conv2d_164 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_165 (Conv2D)         (None, 8, 8, 2048)        1050624   \n",
      "                                                                 \n",
      " conv2d_166 (Conv2D)         (None, 8, 8, 512)         1049088   \n",
      "                                                                 \n",
      " conv2d_167 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_168 (Conv2D)         (None, 8, 8, 2048)        1050624   \n",
      "                                                                 \n",
      " conv2d_169 (Conv2D)         (None, 8, 8, 512)         1049088   \n",
      "                                                                 \n",
      " conv2d_170 (Conv2D)         (None, 8, 8, 512)         2359808   \n",
      "                                                                 \n",
      " conv2d_171 (Conv2D)         (None, 8, 8, 2048)        1050624   \n",
      "                                                                 \n",
      " average_pooling2d_14 (Avera  (None, 2, 2, 2048)       0         \n",
      " gePooling2D)                                                    \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 100)               819300    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,689,700\n",
      "Trainable params: 14,689,700\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#inputs = tf.keras.Input(shape=(32,32,3))\n",
    "#x = model_16(inputs)\n",
    "#x = model_32(x)\n",
    "import os\n",
    "\n",
    "vanilla_model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.Input(shape=(32,32,3)),\n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(64, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(64, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(256, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(128, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(128, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.MaxPooling2D(pool_size=(3, 3), strides=(2,2), padding=\"same\"),\n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(512, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(512, 3, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.Conv2D(2048, 1, padding=\"same\", activation='relu'),\n",
    "        tf.keras.layers.AveragePooling2D(pool_size=(7,7), strides=(1, 1), padding='valid'),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(100, activation=\"softmax\")\n",
    "    ], name = \"vanilla_model\"\n",
    ")\n",
    "run_logdir = get_run_logdir(\"VanillaModel_Large_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "metrics = [tf.keras.metrics.MeanAbsoluteError(name=\"mae\"),\n",
    "            tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\")]\n",
    "\n",
    "vanilla_model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=metrics)\n",
    "\n",
    "vanilla_model.summary()\n",
    "#history = vanilla_model.fit(train_dataset, epochs=50, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1c9b998e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "391/391 [==============================] - 43s 81ms/step - loss: 3.6928 - mae: 0.0098 - categorical_accuracy: 0.5534 - lr: 3.0000e-04\n",
      "Epoch 2/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 2.9840 - mae: 0.0170 - categorical_accuracy: 0.2594 - lr: 3.0000e-04\n",
      "Epoch 3/100\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 2.5387 - mae: 0.0156 - categorical_accuracy: 0.3450 - lr: 3.0000e-04\n",
      "Epoch 4/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 2.1772 - mae: 0.0143 - categorical_accuracy: 0.4222 - lr: 3.0000e-04\n",
      "Epoch 5/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 1.8577 - mae: 0.0130 - categorical_accuracy: 0.4936 - lr: 3.0000e-04\n",
      "Epoch 6/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 1.5476 - mae: 0.0116 - categorical_accuracy: 0.5675 - lr: 3.0000e-04\n",
      "Epoch 7/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 1.2219 - mae: 0.0099 - categorical_accuracy: 0.6501 - lr: 3.0000e-04\n",
      "Epoch 8/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 0.9478 - mae: 0.0084 - categorical_accuracy: 0.7228 - lr: 3.0000e-04\n",
      "Epoch 9/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 0.7165 - mae: 0.0068 - categorical_accuracy: 0.7885 - lr: 3.0000e-04\n",
      "Epoch 10/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 0.5537 - mae: 0.0056 - categorical_accuracy: 0.8337 - lr: 3.0000e-04\n",
      "Epoch 11/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.4536 - mae: 0.0047 - categorical_accuracy: 0.8628 - lr: 3.0000e-04\n",
      "Epoch 12/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.3849 - mae: 0.0041 - categorical_accuracy: 0.8806 - lr: 3.0000e-04\n",
      "Epoch 13/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.3231 - mae: 0.0035 - categorical_accuracy: 0.9006 - lr: 3.0000e-04\n",
      "Epoch 14/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.2961 - mae: 0.0032 - categorical_accuracy: 0.9058 - lr: 3.0000e-04\n",
      "Epoch 15/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.2697 - mae: 0.0029 - categorical_accuracy: 0.9149 - lr: 3.0000e-04\n",
      "Epoch 16/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.2392 - mae: 0.0026 - categorical_accuracy: 0.9247 - lr: 3.0000e-04\n",
      "Epoch 17/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.2320 - mae: 0.0025 - categorical_accuracy: 0.9264 - lr: 3.0000e-04\n",
      "Epoch 18/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.2292 - mae: 0.0024 - categorical_accuracy: 0.9272 - lr: 3.0000e-04\n",
      "Epoch 19/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.2056 - mae: 0.0022 - categorical_accuracy: 0.9346 - lr: 3.0000e-04\n",
      "Epoch 20/100\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 0.1912 - mae: 0.0020 - categorical_accuracy: 0.9391 - lr: 3.0000e-04\n",
      "Epoch 21/100\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 0.1995 - mae: 0.0021 - categorical_accuracy: 0.9360 - lr: 3.0000e-04\n",
      "Epoch 22/100\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 0.1753 - mae: 0.0019 - categorical_accuracy: 0.9421 - lr: 3.0000e-04\n",
      "Epoch 23/100\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 0.1608 - mae: 0.0017 - categorical_accuracy: 0.9491 - lr: 3.0000e-04\n",
      "Epoch 24/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1777 - mae: 0.0018 - categorical_accuracy: 0.9426 - lr: 3.0000e-04\n",
      "Epoch 25/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1626 - mae: 0.0017 - categorical_accuracy: 0.9480 - lr: 3.0000e-04\n",
      "Epoch 26/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1701 - mae: 0.0017 - categorical_accuracy: 0.9444 - lr: 3.0000e-04\n",
      "Epoch 27/100\n",
      "391/391 [==============================] - 32s 82ms/step - loss: 0.1474 - mae: 0.0015 - categorical_accuracy: 0.9523 - lr: 3.0000e-04\n",
      "Epoch 28/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 0.1353 - mae: 0.0014 - categorical_accuracy: 0.9562 - lr: 3.0000e-04\n",
      "Epoch 29/100\n",
      "391/391 [==============================] - 31s 78ms/step - loss: 0.1345 - mae: 0.0014 - categorical_accuracy: 0.9559 - lr: 3.0000e-04\n",
      "Epoch 30/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1263 - mae: 0.0013 - categorical_accuracy: 0.9598 - lr: 3.0000e-04\n",
      "Epoch 31/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1436 - mae: 0.0014 - categorical_accuracy: 0.9547 - lr: 3.0000e-04\n",
      "Epoch 32/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1385 - mae: 0.0014 - categorical_accuracy: 0.9549 - lr: 3.0000e-04\n",
      "Epoch 33/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1237 - mae: 0.0013 - categorical_accuracy: 0.9592 - lr: 3.0000e-04\n",
      "Epoch 34/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1178 - mae: 0.0012 - categorical_accuracy: 0.9619 - lr: 3.0000e-04\n",
      "Epoch 35/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1211 - mae: 0.0012 - categorical_accuracy: 0.9608 - lr: 3.0000e-04\n",
      "Epoch 36/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1151 - mae: 0.0012 - categorical_accuracy: 0.9635 - lr: 3.0000e-04\n",
      "Epoch 37/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1062 - mae: 0.0011 - categorical_accuracy: 0.9655 - lr: 3.0000e-04\n",
      "Epoch 38/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0978 - mae: 0.0010 - categorical_accuracy: 0.9682 - lr: 3.0000e-04\n",
      "Epoch 39/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1025 - mae: 0.0011 - categorical_accuracy: 0.9666 - lr: 3.0000e-04\n",
      "Epoch 40/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.1117 - mae: 0.0011 - categorical_accuracy: 0.9635 - lr: 3.0000e-04\n",
      "Epoch 41/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.1052 - mae: 0.0011 - categorical_accuracy: 0.9666 - lr: 3.0000e-04\n",
      "Epoch 42/100\n",
      "391/391 [==============================] - 33s 85ms/step - loss: 0.0990 - mae: 0.0010 - categorical_accuracy: 0.9687 - lr: 3.0000e-04\n",
      "Epoch 43/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0987 - mae: 0.0010 - categorical_accuracy: 0.9681 - lr: 3.0000e-04\n",
      "Epoch 44/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0960 - mae: 9.7758e-04 - categorical_accuracy: 0.9693 - lr: 3.0000e-04\n",
      "Epoch 45/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0917 - mae: 9.4317e-04 - categorical_accuracy: 0.9701 - lr: 3.0000e-04\n",
      "Epoch 46/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0909 - mae: 9.4730e-04 - categorical_accuracy: 0.9700 - lr: 3.0000e-04\n",
      "Epoch 47/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0781 - mae: 8.1067e-04 - categorical_accuracy: 0.9752 - lr: 3.0000e-04\n",
      "Epoch 48/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0828 - mae: 8.3886e-04 - categorical_accuracy: 0.9737 - lr: 3.0000e-04\n",
      "Epoch 49/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0932 - mae: 9.2561e-04 - categorical_accuracy: 0.9706 - lr: 3.0000e-04\n",
      "Epoch 50/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0847 - mae: 8.6365e-04 - categorical_accuracy: 0.9726 - lr: 3.0000e-04\n",
      "Epoch 51/100\n",
      "391/391 [==============================] - 32s 81ms/step - loss: 0.0815 - mae: 8.3369e-04 - categorical_accuracy: 0.9732 - lr: 3.0000e-04\n",
      "Epoch 52/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0877 - mae: 8.7350e-04 - categorical_accuracy: 0.9715 - lr: 3.0000e-04\n",
      "Epoch 53/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0830 - mae: 8.2381e-04 - categorical_accuracy: 0.9734 - lr: 3.0000e-04\n",
      "Epoch 54/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0689 - mae: 7.1542e-04 - categorical_accuracy: 0.9775 - lr: 3.0000e-04\n",
      "Epoch 55/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0711 - mae: 7.2423e-04 - categorical_accuracy: 0.9772 - lr: 3.0000e-04\n",
      "Epoch 56/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0795 - mae: 8.0175e-04 - categorical_accuracy: 0.9738 - lr: 3.0000e-04\n",
      "Epoch 57/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0740 - mae: 7.5496e-04 - categorical_accuracy: 0.9760 - lr: 3.0000e-04\n",
      "Epoch 58/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0735 - mae: 7.4896e-04 - categorical_accuracy: 0.9757 - lr: 3.0000e-04\n",
      "Epoch 59/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0745 - mae: 7.4347e-04 - categorical_accuracy: 0.9755 - lr: 3.0000e-04\n",
      "Epoch 60/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0740 - mae: 7.4791e-04 - categorical_accuracy: 0.9759 - lr: 3.0000e-04\n",
      "Epoch 61/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0748 - mae: 7.4326e-04 - categorical_accuracy: 0.9753 - lr: 3.0000e-04\n",
      "Epoch 62/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0454 - mae: 4.8694e-04 - categorical_accuracy: 0.9855 - lr: 3.0000e-05\n",
      "Epoch 63/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0101 - mae: 1.3811e-04 - categorical_accuracy: 0.9982 - lr: 3.0000e-05\n",
      "Epoch 64/100\n",
      "391/391 [==============================] - 31s 79ms/step - loss: 0.0059 - mae: 8.1555e-05 - categorical_accuracy: 0.9992 - lr: 3.0000e-05\n",
      "Epoch 65/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0058 - mae: 7.2552e-05 - categorical_accuracy: 0.9991 - lr: 3.0000e-05\n",
      "Epoch 66/100\n",
      "391/391 [==============================] - 31s 80ms/step - loss: 0.0054 - mae: 5.9660e-05 - categorical_accuracy: 0.9993 - lr: 3.0000e-05\n",
      "Epoch 67/100\n",
      "307/391 [======================>.......] - ETA: 6s - loss: 0.0045 - mae: 5.0306e-05 - categorical_accuracy: 0.9993"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_80774/1966916320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m                    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=[metrics])\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#model_temp.summary()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel_temp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3128\u001b[0m       (graph_function,\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3130\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3131\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1957\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1959\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1960\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    599\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/ml/my_env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     59\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_logdir = get_run_logdir(\"DenseNet201_Cifar100\")\n",
    "callback = [tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', patience=7),\n",
    "            tf.keras.callbacks.TensorBoard(run_logdir)]\n",
    "\n",
    "model_temp = tf.keras.applications.DenseNet201(weights=None, input_shape=(32,32,3), classes=100)\n",
    "model_temp.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "                   optimizer=tf.keras.optimizers.Adam(learning_rate=0.0003), metrics=[metrics])\n",
    "#model_temp.summary()\n",
    "model_temp.fit(train_dataset, epochs=100, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "687c6213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"densenet201\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_11 (InputLayer)          [(None, 32, 32, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadding2  (None, 38, 38, 3)   0           ['input_11[0][0]']               \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv1/conv (Conv2D)            (None, 16, 16, 64)   9408        ['zero_padding2d_6[0][0]']       \n",
      "                                                                                                  \n",
      " conv1/bn (BatchNormalization)  (None, 16, 16, 64)   256         ['conv1/conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv1/relu (Activation)        (None, 16, 16, 64)   0           ['conv1/bn[0][0]']               \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadding2  (None, 18, 18, 64)  0           ['conv1/relu[0][0]']             \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " pool1 (MaxPooling2D)           (None, 8, 8, 64)     0           ['zero_padding2d_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 8, 8, 64)    256         ['pool1[0][0]']                  \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_0_relu (Activatio  (None, 8, 8, 64)    0           ['conv2_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 8, 8, 128)    8192        ['conv2_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_concat (Concatena  (None, 8, 8, 96)    0           ['pool1[0][0]',                  \n",
      " te)                                                              'conv2_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_0_bn (BatchNormal  (None, 8, 8, 96)    384         ['conv2_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_0_relu (Activatio  (None, 8, 8, 96)    0           ['conv2_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 8, 8, 128)    12288       ['conv2_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_concat (Concatena  (None, 8, 8, 128)   0           ['conv2_block1_concat[0][0]',    \n",
      " te)                                                              'conv2_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_0_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_0_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 8, 8, 128)    16384       ['conv2_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_concat (Concatena  (None, 8, 8, 160)   0           ['conv2_block2_concat[0][0]',    \n",
      " te)                                                              'conv2_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_0_bn (BatchNormal  (None, 8, 8, 160)   640         ['conv2_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_0_relu (Activatio  (None, 8, 8, 160)   0           ['conv2_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_1_conv (Conv2D)   (None, 8, 8, 128)    20480       ['conv2_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block4_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block4_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block4_concat (Concatena  (None, 8, 8, 192)   0           ['conv2_block3_concat[0][0]',    \n",
      " te)                                                              'conv2_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_0_bn (BatchNormal  (None, 8, 8, 192)   768         ['conv2_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_0_relu (Activatio  (None, 8, 8, 192)   0           ['conv2_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_1_conv (Conv2D)   (None, 8, 8, 128)    24576       ['conv2_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block5_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block5_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block5_concat (Concatena  (None, 8, 8, 224)   0           ['conv2_block4_concat[0][0]',    \n",
      " te)                                                              'conv2_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_0_bn (BatchNormal  (None, 8, 8, 224)   896         ['conv2_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_0_relu (Activatio  (None, 8, 8, 224)   0           ['conv2_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_1_conv (Conv2D)   (None, 8, 8, 128)    28672       ['conv2_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_1_bn (BatchNormal  (None, 8, 8, 128)   512         ['conv2_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block6_1_relu (Activatio  (None, 8, 8, 128)   0           ['conv2_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block6_2_conv (Conv2D)   (None, 8, 8, 32)     36864       ['conv2_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block6_concat (Concatena  (None, 8, 8, 256)   0           ['conv2_block5_concat[0][0]',    \n",
      " te)                                                              'conv2_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_bn (BatchNormalization)  (None, 8, 8, 256)    1024        ['conv2_block6_concat[0][0]']    \n",
      "                                                                                                  \n",
      " pool2_relu (Activation)        (None, 8, 8, 256)    0           ['pool2_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool2_conv (Conv2D)            (None, 8, 8, 128)    32768       ['pool2_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool2_pool (AveragePooling2D)  (None, 4, 4, 128)    0           ['pool2_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 4, 4, 128)   512         ['pool2_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_0_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 4, 4, 128)    16384       ['conv3_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_concat (Concatena  (None, 4, 4, 160)   0           ['pool2_pool[0][0]',             \n",
      " te)                                                              'conv3_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_0_bn (BatchNormal  (None, 4, 4, 160)   640         ['conv3_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_0_relu (Activatio  (None, 4, 4, 160)   0           ['conv3_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 4, 4, 128)    20480       ['conv3_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_concat (Concatena  (None, 4, 4, 192)   0           ['conv3_block1_concat[0][0]',    \n",
      " te)                                                              'conv3_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_0_bn (BatchNormal  (None, 4, 4, 192)   768         ['conv3_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_0_relu (Activatio  (None, 4, 4, 192)   0           ['conv3_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 4, 4, 128)    24576       ['conv3_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_concat (Concatena  (None, 4, 4, 224)   0           ['conv3_block2_concat[0][0]',    \n",
      " te)                                                              'conv3_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_0_bn (BatchNormal  (None, 4, 4, 224)   896         ['conv3_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_0_relu (Activatio  (None, 4, 4, 224)   0           ['conv3_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 4, 4, 128)    28672       ['conv3_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_concat (Concatena  (None, 4, 4, 256)   0           ['conv3_block3_concat[0][0]',    \n",
      " te)                                                              'conv3_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_0_bn (BatchNormal  (None, 4, 4, 256)   1024        ['conv3_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_0_relu (Activatio  (None, 4, 4, 256)   0           ['conv3_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_1_conv (Conv2D)   (None, 4, 4, 128)    32768       ['conv3_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block5_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block5_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block5_concat (Concatena  (None, 4, 4, 288)   0           ['conv3_block4_concat[0][0]',    \n",
      " te)                                                              'conv3_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_0_bn (BatchNormal  (None, 4, 4, 288)   1152        ['conv3_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_0_relu (Activatio  (None, 4, 4, 288)   0           ['conv3_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_1_conv (Conv2D)   (None, 4, 4, 128)    36864       ['conv3_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block6_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block6_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block6_concat (Concatena  (None, 4, 4, 320)   0           ['conv3_block5_concat[0][0]',    \n",
      " te)                                                              'conv3_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_0_bn (BatchNormal  (None, 4, 4, 320)   1280        ['conv3_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_0_relu (Activatio  (None, 4, 4, 320)   0           ['conv3_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_1_conv (Conv2D)   (None, 4, 4, 128)    40960       ['conv3_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block7_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block7_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block7_concat (Concatena  (None, 4, 4, 352)   0           ['conv3_block6_concat[0][0]',    \n",
      " te)                                                              'conv3_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_0_bn (BatchNormal  (None, 4, 4, 352)   1408        ['conv3_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_0_relu (Activatio  (None, 4, 4, 352)   0           ['conv3_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_1_conv (Conv2D)   (None, 4, 4, 128)    45056       ['conv3_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block8_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block8_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block8_concat (Concatena  (None, 4, 4, 384)   0           ['conv3_block7_concat[0][0]',    \n",
      " te)                                                              'conv3_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_0_bn (BatchNormal  (None, 4, 4, 384)   1536        ['conv3_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_0_relu (Activatio  (None, 4, 4, 384)   0           ['conv3_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_1_conv (Conv2D)   (None, 4, 4, 128)    49152       ['conv3_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_1_bn (BatchNormal  (None, 4, 4, 128)   512         ['conv3_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block9_1_relu (Activatio  (None, 4, 4, 128)   0           ['conv3_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block9_2_conv (Conv2D)   (None, 4, 4, 32)     36864       ['conv3_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block9_concat (Concatena  (None, 4, 4, 416)   0           ['conv3_block8_concat[0][0]',    \n",
      " te)                                                              'conv3_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block10_0_bn (BatchNorma  (None, 4, 4, 416)   1664        ['conv3_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_0_relu (Activati  (None, 4, 4, 416)   0           ['conv3_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_1_conv (Conv2D)  (None, 4, 4, 128)    53248       ['conv3_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block10_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block10_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block10_concat (Concaten  (None, 4, 4, 448)   0           ['conv3_block9_concat[0][0]',    \n",
      " ate)                                                             'conv3_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_0_bn (BatchNorma  (None, 4, 4, 448)   1792        ['conv3_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_0_relu (Activati  (None, 4, 4, 448)   0           ['conv3_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_1_conv (Conv2D)  (None, 4, 4, 128)    57344       ['conv3_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block11_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block11_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block11_concat (Concaten  (None, 4, 4, 480)   0           ['conv3_block10_concat[0][0]',   \n",
      " ate)                                                             'conv3_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_0_bn (BatchNorma  (None, 4, 4, 480)   1920        ['conv3_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_0_relu (Activati  (None, 4, 4, 480)   0           ['conv3_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_1_conv (Conv2D)  (None, 4, 4, 128)    61440       ['conv3_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_1_bn (BatchNorma  (None, 4, 4, 128)   512         ['conv3_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv3_block12_1_relu (Activati  (None, 4, 4, 128)   0           ['conv3_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv3_block12_2_conv (Conv2D)  (None, 4, 4, 32)     36864       ['conv3_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv3_block12_concat (Concaten  (None, 4, 4, 512)   0           ['conv3_block11_concat[0][0]',   \n",
      " ate)                                                             'conv3_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_bn (BatchNormalization)  (None, 4, 4, 512)    2048        ['conv3_block12_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool3_relu (Activation)        (None, 4, 4, 512)    0           ['pool3_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool3_conv (Conv2D)            (None, 4, 4, 256)    131072      ['pool3_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool3_pool (AveragePooling2D)  (None, 2, 2, 256)    0           ['pool3_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 2, 2, 256)   1024        ['pool3_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_0_relu (Activatio  (None, 2, 2, 256)   0           ['conv4_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 2, 2, 128)    32768       ['conv4_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_concat (Concatena  (None, 2, 2, 288)   0           ['pool3_pool[0][0]',             \n",
      " te)                                                              'conv4_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_0_bn (BatchNormal  (None, 2, 2, 288)   1152        ['conv4_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_0_relu (Activatio  (None, 2, 2, 288)   0           ['conv4_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 2, 2, 128)    36864       ['conv4_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_concat (Concatena  (None, 2, 2, 320)   0           ['conv4_block1_concat[0][0]',    \n",
      " te)                                                              'conv4_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_0_bn (BatchNormal  (None, 2, 2, 320)   1280        ['conv4_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_0_relu (Activatio  (None, 2, 2, 320)   0           ['conv4_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 2, 2, 128)    40960       ['conv4_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_concat (Concatena  (None, 2, 2, 352)   0           ['conv4_block2_concat[0][0]',    \n",
      " te)                                                              'conv4_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_0_bn (BatchNormal  (None, 2, 2, 352)   1408        ['conv4_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_0_relu (Activatio  (None, 2, 2, 352)   0           ['conv4_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 2, 2, 128)    45056       ['conv4_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_concat (Concatena  (None, 2, 2, 384)   0           ['conv4_block3_concat[0][0]',    \n",
      " te)                                                              'conv4_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_0_bn (BatchNormal  (None, 2, 2, 384)   1536        ['conv4_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_0_relu (Activatio  (None, 2, 2, 384)   0           ['conv4_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 2, 2, 128)    49152       ['conv4_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_concat (Concatena  (None, 2, 2, 416)   0           ['conv4_block4_concat[0][0]',    \n",
      " te)                                                              'conv4_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_0_bn (BatchNormal  (None, 2, 2, 416)   1664        ['conv4_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_0_relu (Activatio  (None, 2, 2, 416)   0           ['conv4_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 2, 2, 128)    53248       ['conv4_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_concat (Concatena  (None, 2, 2, 448)   0           ['conv4_block5_concat[0][0]',    \n",
      " te)                                                              'conv4_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_0_bn (BatchNormal  (None, 2, 2, 448)   1792        ['conv4_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_0_relu (Activatio  (None, 2, 2, 448)   0           ['conv4_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_1_conv (Conv2D)   (None, 2, 2, 128)    57344       ['conv4_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block7_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block7_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block7_concat (Concatena  (None, 2, 2, 480)   0           ['conv4_block6_concat[0][0]',    \n",
      " te)                                                              'conv4_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_0_bn (BatchNormal  (None, 2, 2, 480)   1920        ['conv4_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_0_relu (Activatio  (None, 2, 2, 480)   0           ['conv4_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_1_conv (Conv2D)   (None, 2, 2, 128)    61440       ['conv4_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block8_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block8_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block8_concat (Concatena  (None, 2, 2, 512)   0           ['conv4_block7_concat[0][0]',    \n",
      " te)                                                              'conv4_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_0_bn (BatchNormal  (None, 2, 2, 512)   2048        ['conv4_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_0_relu (Activatio  (None, 2, 2, 512)   0           ['conv4_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_1_conv (Conv2D)   (None, 2, 2, 128)    65536       ['conv4_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_1_bn (BatchNormal  (None, 2, 2, 128)   512         ['conv4_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block9_1_relu (Activatio  (None, 2, 2, 128)   0           ['conv4_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block9_2_conv (Conv2D)   (None, 2, 2, 32)     36864       ['conv4_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block9_concat (Concatena  (None, 2, 2, 544)   0           ['conv4_block8_concat[0][0]',    \n",
      " te)                                                              'conv4_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block10_0_bn (BatchNorma  (None, 2, 2, 544)   2176        ['conv4_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_0_relu (Activati  (None, 2, 2, 544)   0           ['conv4_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_1_conv (Conv2D)  (None, 2, 2, 128)    69632       ['conv4_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block10_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block10_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block10_concat (Concaten  (None, 2, 2, 576)   0           ['conv4_block9_concat[0][0]',    \n",
      " ate)                                                             'conv4_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_0_bn (BatchNorma  (None, 2, 2, 576)   2304        ['conv4_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_0_relu (Activati  (None, 2, 2, 576)   0           ['conv4_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_1_conv (Conv2D)  (None, 2, 2, 128)    73728       ['conv4_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block11_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block11_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block11_concat (Concaten  (None, 2, 2, 608)   0           ['conv4_block10_concat[0][0]',   \n",
      " ate)                                                             'conv4_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_0_bn (BatchNorma  (None, 2, 2, 608)   2432        ['conv4_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_0_relu (Activati  (None, 2, 2, 608)   0           ['conv4_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_1_conv (Conv2D)  (None, 2, 2, 128)    77824       ['conv4_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block12_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block12_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block12_concat (Concaten  (None, 2, 2, 640)   0           ['conv4_block11_concat[0][0]',   \n",
      " ate)                                                             'conv4_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_0_bn (BatchNorma  (None, 2, 2, 640)   2560        ['conv4_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_0_relu (Activati  (None, 2, 2, 640)   0           ['conv4_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_1_conv (Conv2D)  (None, 2, 2, 128)    81920       ['conv4_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block13_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block13_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block13_concat (Concaten  (None, 2, 2, 672)   0           ['conv4_block12_concat[0][0]',   \n",
      " ate)                                                             'conv4_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_0_bn (BatchNorma  (None, 2, 2, 672)   2688        ['conv4_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_0_relu (Activati  (None, 2, 2, 672)   0           ['conv4_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_1_conv (Conv2D)  (None, 2, 2, 128)    86016       ['conv4_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block14_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block14_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block14_concat (Concaten  (None, 2, 2, 704)   0           ['conv4_block13_concat[0][0]',   \n",
      " ate)                                                             'conv4_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_0_bn (BatchNorma  (None, 2, 2, 704)   2816        ['conv4_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_0_relu (Activati  (None, 2, 2, 704)   0           ['conv4_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_1_conv (Conv2D)  (None, 2, 2, 128)    90112       ['conv4_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block15_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block15_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block15_concat (Concaten  (None, 2, 2, 736)   0           ['conv4_block14_concat[0][0]',   \n",
      " ate)                                                             'conv4_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_0_bn (BatchNorma  (None, 2, 2, 736)   2944        ['conv4_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_0_relu (Activati  (None, 2, 2, 736)   0           ['conv4_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_1_conv (Conv2D)  (None, 2, 2, 128)    94208       ['conv4_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block16_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block16_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block16_concat (Concaten  (None, 2, 2, 768)   0           ['conv4_block15_concat[0][0]',   \n",
      " ate)                                                             'conv4_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_0_bn (BatchNorma  (None, 2, 2, 768)   3072        ['conv4_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_0_relu (Activati  (None, 2, 2, 768)   0           ['conv4_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_1_conv (Conv2D)  (None, 2, 2, 128)    98304       ['conv4_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block17_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block17_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block17_concat (Concaten  (None, 2, 2, 800)   0           ['conv4_block16_concat[0][0]',   \n",
      " ate)                                                             'conv4_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_0_bn (BatchNorma  (None, 2, 2, 800)   3200        ['conv4_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_0_relu (Activati  (None, 2, 2, 800)   0           ['conv4_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_1_conv (Conv2D)  (None, 2, 2, 128)    102400      ['conv4_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block18_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block18_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block18_concat (Concaten  (None, 2, 2, 832)   0           ['conv4_block17_concat[0][0]',   \n",
      " ate)                                                             'conv4_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_0_bn (BatchNorma  (None, 2, 2, 832)   3328        ['conv4_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_0_relu (Activati  (None, 2, 2, 832)   0           ['conv4_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_1_conv (Conv2D)  (None, 2, 2, 128)    106496      ['conv4_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block19_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block19_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block19_concat (Concaten  (None, 2, 2, 864)   0           ['conv4_block18_concat[0][0]',   \n",
      " ate)                                                             'conv4_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_0_bn (BatchNorma  (None, 2, 2, 864)   3456        ['conv4_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_0_relu (Activati  (None, 2, 2, 864)   0           ['conv4_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_1_conv (Conv2D)  (None, 2, 2, 128)    110592      ['conv4_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block20_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block20_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block20_concat (Concaten  (None, 2, 2, 896)   0           ['conv4_block19_concat[0][0]',   \n",
      " ate)                                                             'conv4_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_0_bn (BatchNorma  (None, 2, 2, 896)   3584        ['conv4_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_0_relu (Activati  (None, 2, 2, 896)   0           ['conv4_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_1_conv (Conv2D)  (None, 2, 2, 128)    114688      ['conv4_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block21_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block21_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block21_concat (Concaten  (None, 2, 2, 928)   0           ['conv4_block20_concat[0][0]',   \n",
      " ate)                                                             'conv4_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_0_bn (BatchNorma  (None, 2, 2, 928)   3712        ['conv4_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_0_relu (Activati  (None, 2, 2, 928)   0           ['conv4_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_1_conv (Conv2D)  (None, 2, 2, 128)    118784      ['conv4_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block22_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block22_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block22_concat (Concaten  (None, 2, 2, 960)   0           ['conv4_block21_concat[0][0]',   \n",
      " ate)                                                             'conv4_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_0_bn (BatchNorma  (None, 2, 2, 960)   3840        ['conv4_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_0_relu (Activati  (None, 2, 2, 960)   0           ['conv4_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_1_conv (Conv2D)  (None, 2, 2, 128)    122880      ['conv4_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block23_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block23_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block23_concat (Concaten  (None, 2, 2, 992)   0           ['conv4_block22_concat[0][0]',   \n",
      " ate)                                                             'conv4_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_0_bn (BatchNorma  (None, 2, 2, 992)   3968        ['conv4_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_0_relu (Activati  (None, 2, 2, 992)   0           ['conv4_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_1_conv (Conv2D)  (None, 2, 2, 128)    126976      ['conv4_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block24_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block24_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block24_concat (Concaten  (None, 2, 2, 1024)  0           ['conv4_block23_concat[0][0]',   \n",
      " ate)                                                             'conv4_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_0_bn (BatchNorma  (None, 2, 2, 1024)  4096        ['conv4_block24_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block25_0_relu (Activati  (None, 2, 2, 1024)  0           ['conv4_block25_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block25_1_conv (Conv2D)  (None, 2, 2, 128)    131072      ['conv4_block25_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block25_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block25_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block25_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block25_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block25_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block25_concat (Concaten  (None, 2, 2, 1056)  0           ['conv4_block24_concat[0][0]',   \n",
      " ate)                                                             'conv4_block25_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_0_bn (BatchNorma  (None, 2, 2, 1056)  4224        ['conv4_block25_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block26_0_relu (Activati  (None, 2, 2, 1056)  0           ['conv4_block26_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block26_1_conv (Conv2D)  (None, 2, 2, 128)    135168      ['conv4_block26_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block26_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block26_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block26_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block26_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block26_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block26_concat (Concaten  (None, 2, 2, 1088)  0           ['conv4_block25_concat[0][0]',   \n",
      " ate)                                                             'conv4_block26_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_0_bn (BatchNorma  (None, 2, 2, 1088)  4352        ['conv4_block26_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block27_0_relu (Activati  (None, 2, 2, 1088)  0           ['conv4_block27_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block27_1_conv (Conv2D)  (None, 2, 2, 128)    139264      ['conv4_block27_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block27_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block27_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block27_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block27_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block27_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block27_concat (Concaten  (None, 2, 2, 1120)  0           ['conv4_block26_concat[0][0]',   \n",
      " ate)                                                             'conv4_block27_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_0_bn (BatchNorma  (None, 2, 2, 1120)  4480        ['conv4_block27_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block28_0_relu (Activati  (None, 2, 2, 1120)  0           ['conv4_block28_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block28_1_conv (Conv2D)  (None, 2, 2, 128)    143360      ['conv4_block28_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block28_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block28_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block28_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block28_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block28_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block28_concat (Concaten  (None, 2, 2, 1152)  0           ['conv4_block27_concat[0][0]',   \n",
      " ate)                                                             'conv4_block28_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_0_bn (BatchNorma  (None, 2, 2, 1152)  4608        ['conv4_block28_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block29_0_relu (Activati  (None, 2, 2, 1152)  0           ['conv4_block29_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block29_1_conv (Conv2D)  (None, 2, 2, 128)    147456      ['conv4_block29_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block29_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block29_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block29_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block29_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block29_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block29_concat (Concaten  (None, 2, 2, 1184)  0           ['conv4_block28_concat[0][0]',   \n",
      " ate)                                                             'conv4_block29_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_0_bn (BatchNorma  (None, 2, 2, 1184)  4736        ['conv4_block29_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block30_0_relu (Activati  (None, 2, 2, 1184)  0           ['conv4_block30_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block30_1_conv (Conv2D)  (None, 2, 2, 128)    151552      ['conv4_block30_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block30_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block30_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block30_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block30_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block30_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block30_concat (Concaten  (None, 2, 2, 1216)  0           ['conv4_block29_concat[0][0]',   \n",
      " ate)                                                             'conv4_block30_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_0_bn (BatchNorma  (None, 2, 2, 1216)  4864        ['conv4_block30_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block31_0_relu (Activati  (None, 2, 2, 1216)  0           ['conv4_block31_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block31_1_conv (Conv2D)  (None, 2, 2, 128)    155648      ['conv4_block31_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block31_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block31_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block31_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block31_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block31_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block31_concat (Concaten  (None, 2, 2, 1248)  0           ['conv4_block30_concat[0][0]',   \n",
      " ate)                                                             'conv4_block31_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_0_bn (BatchNorma  (None, 2, 2, 1248)  4992        ['conv4_block31_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block32_0_relu (Activati  (None, 2, 2, 1248)  0           ['conv4_block32_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block32_1_conv (Conv2D)  (None, 2, 2, 128)    159744      ['conv4_block32_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block32_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block32_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block32_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block32_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block32_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block32_concat (Concaten  (None, 2, 2, 1280)  0           ['conv4_block31_concat[0][0]',   \n",
      " ate)                                                             'conv4_block32_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block33_0_bn (BatchNorma  (None, 2, 2, 1280)  5120        ['conv4_block32_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block33_0_relu (Activati  (None, 2, 2, 1280)  0           ['conv4_block33_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block33_1_conv (Conv2D)  (None, 2, 2, 128)    163840      ['conv4_block33_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block33_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block33_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block33_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block33_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block33_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block33_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block33_concat (Concaten  (None, 2, 2, 1312)  0           ['conv4_block32_concat[0][0]',   \n",
      " ate)                                                             'conv4_block33_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block34_0_bn (BatchNorma  (None, 2, 2, 1312)  5248        ['conv4_block33_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block34_0_relu (Activati  (None, 2, 2, 1312)  0           ['conv4_block34_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block34_1_conv (Conv2D)  (None, 2, 2, 128)    167936      ['conv4_block34_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block34_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block34_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block34_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block34_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block34_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block34_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block34_concat (Concaten  (None, 2, 2, 1344)  0           ['conv4_block33_concat[0][0]',   \n",
      " ate)                                                             'conv4_block34_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block35_0_bn (BatchNorma  (None, 2, 2, 1344)  5376        ['conv4_block34_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block35_0_relu (Activati  (None, 2, 2, 1344)  0           ['conv4_block35_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block35_1_conv (Conv2D)  (None, 2, 2, 128)    172032      ['conv4_block35_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block35_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block35_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block35_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block35_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block35_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block35_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block35_concat (Concaten  (None, 2, 2, 1376)  0           ['conv4_block34_concat[0][0]',   \n",
      " ate)                                                             'conv4_block35_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block36_0_bn (BatchNorma  (None, 2, 2, 1376)  5504        ['conv4_block35_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block36_0_relu (Activati  (None, 2, 2, 1376)  0           ['conv4_block36_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block36_1_conv (Conv2D)  (None, 2, 2, 128)    176128      ['conv4_block36_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block36_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block36_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block36_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block36_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block36_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block36_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block36_concat (Concaten  (None, 2, 2, 1408)  0           ['conv4_block35_concat[0][0]',   \n",
      " ate)                                                             'conv4_block36_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block37_0_bn (BatchNorma  (None, 2, 2, 1408)  5632        ['conv4_block36_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block37_0_relu (Activati  (None, 2, 2, 1408)  0           ['conv4_block37_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block37_1_conv (Conv2D)  (None, 2, 2, 128)    180224      ['conv4_block37_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block37_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block37_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block37_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block37_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block37_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block37_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block37_concat (Concaten  (None, 2, 2, 1440)  0           ['conv4_block36_concat[0][0]',   \n",
      " ate)                                                             'conv4_block37_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block38_0_bn (BatchNorma  (None, 2, 2, 1440)  5760        ['conv4_block37_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block38_0_relu (Activati  (None, 2, 2, 1440)  0           ['conv4_block38_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block38_1_conv (Conv2D)  (None, 2, 2, 128)    184320      ['conv4_block38_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block38_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block38_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block38_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block38_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block38_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block38_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block38_concat (Concaten  (None, 2, 2, 1472)  0           ['conv4_block37_concat[0][0]',   \n",
      " ate)                                                             'conv4_block38_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block39_0_bn (BatchNorma  (None, 2, 2, 1472)  5888        ['conv4_block38_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block39_0_relu (Activati  (None, 2, 2, 1472)  0           ['conv4_block39_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block39_1_conv (Conv2D)  (None, 2, 2, 128)    188416      ['conv4_block39_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block39_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block39_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block39_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block39_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block39_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block39_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block39_concat (Concaten  (None, 2, 2, 1504)  0           ['conv4_block38_concat[0][0]',   \n",
      " ate)                                                             'conv4_block39_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block40_0_bn (BatchNorma  (None, 2, 2, 1504)  6016        ['conv4_block39_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block40_0_relu (Activati  (None, 2, 2, 1504)  0           ['conv4_block40_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block40_1_conv (Conv2D)  (None, 2, 2, 128)    192512      ['conv4_block40_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block40_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block40_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block40_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block40_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block40_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block40_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block40_concat (Concaten  (None, 2, 2, 1536)  0           ['conv4_block39_concat[0][0]',   \n",
      " ate)                                                             'conv4_block40_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block41_0_bn (BatchNorma  (None, 2, 2, 1536)  6144        ['conv4_block40_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block41_0_relu (Activati  (None, 2, 2, 1536)  0           ['conv4_block41_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block41_1_conv (Conv2D)  (None, 2, 2, 128)    196608      ['conv4_block41_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block41_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block41_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block41_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block41_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block41_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block41_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block41_concat (Concaten  (None, 2, 2, 1568)  0           ['conv4_block40_concat[0][0]',   \n",
      " ate)                                                             'conv4_block41_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block42_0_bn (BatchNorma  (None, 2, 2, 1568)  6272        ['conv4_block41_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block42_0_relu (Activati  (None, 2, 2, 1568)  0           ['conv4_block42_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block42_1_conv (Conv2D)  (None, 2, 2, 128)    200704      ['conv4_block42_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block42_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block42_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block42_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block42_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block42_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block42_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block42_concat (Concaten  (None, 2, 2, 1600)  0           ['conv4_block41_concat[0][0]',   \n",
      " ate)                                                             'conv4_block42_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block43_0_bn (BatchNorma  (None, 2, 2, 1600)  6400        ['conv4_block42_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block43_0_relu (Activati  (None, 2, 2, 1600)  0           ['conv4_block43_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block43_1_conv (Conv2D)  (None, 2, 2, 128)    204800      ['conv4_block43_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block43_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block43_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block43_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block43_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block43_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block43_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block43_concat (Concaten  (None, 2, 2, 1632)  0           ['conv4_block42_concat[0][0]',   \n",
      " ate)                                                             'conv4_block43_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block44_0_bn (BatchNorma  (None, 2, 2, 1632)  6528        ['conv4_block43_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block44_0_relu (Activati  (None, 2, 2, 1632)  0           ['conv4_block44_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block44_1_conv (Conv2D)  (None, 2, 2, 128)    208896      ['conv4_block44_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block44_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block44_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block44_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block44_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block44_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block44_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block44_concat (Concaten  (None, 2, 2, 1664)  0           ['conv4_block43_concat[0][0]',   \n",
      " ate)                                                             'conv4_block44_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block45_0_bn (BatchNorma  (None, 2, 2, 1664)  6656        ['conv4_block44_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block45_0_relu (Activati  (None, 2, 2, 1664)  0           ['conv4_block45_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block45_1_conv (Conv2D)  (None, 2, 2, 128)    212992      ['conv4_block45_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block45_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block45_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block45_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block45_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block45_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block45_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block45_concat (Concaten  (None, 2, 2, 1696)  0           ['conv4_block44_concat[0][0]',   \n",
      " ate)                                                             'conv4_block45_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block46_0_bn (BatchNorma  (None, 2, 2, 1696)  6784        ['conv4_block45_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block46_0_relu (Activati  (None, 2, 2, 1696)  0           ['conv4_block46_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block46_1_conv (Conv2D)  (None, 2, 2, 128)    217088      ['conv4_block46_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block46_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block46_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block46_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block46_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block46_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block46_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block46_concat (Concaten  (None, 2, 2, 1728)  0           ['conv4_block45_concat[0][0]',   \n",
      " ate)                                                             'conv4_block46_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block47_0_bn (BatchNorma  (None, 2, 2, 1728)  6912        ['conv4_block46_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block47_0_relu (Activati  (None, 2, 2, 1728)  0           ['conv4_block47_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block47_1_conv (Conv2D)  (None, 2, 2, 128)    221184      ['conv4_block47_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block47_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block47_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block47_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block47_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block47_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block47_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block47_concat (Concaten  (None, 2, 2, 1760)  0           ['conv4_block46_concat[0][0]',   \n",
      " ate)                                                             'conv4_block47_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block48_0_bn (BatchNorma  (None, 2, 2, 1760)  7040        ['conv4_block47_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block48_0_relu (Activati  (None, 2, 2, 1760)  0           ['conv4_block48_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block48_1_conv (Conv2D)  (None, 2, 2, 128)    225280      ['conv4_block48_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block48_1_bn (BatchNorma  (None, 2, 2, 128)   512         ['conv4_block48_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv4_block48_1_relu (Activati  (None, 2, 2, 128)   0           ['conv4_block48_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv4_block48_2_conv (Conv2D)  (None, 2, 2, 32)     36864       ['conv4_block48_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv4_block48_concat (Concaten  (None, 2, 2, 1792)  0           ['conv4_block47_concat[0][0]',   \n",
      " ate)                                                             'conv4_block48_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_bn (BatchNormalization)  (None, 2, 2, 1792)   7168        ['conv4_block48_concat[0][0]']   \n",
      "                                                                                                  \n",
      " pool4_relu (Activation)        (None, 2, 2, 1792)   0           ['pool4_bn[0][0]']               \n",
      "                                                                                                  \n",
      " pool4_conv (Conv2D)            (None, 2, 2, 896)    1605632     ['pool4_relu[0][0]']             \n",
      "                                                                                                  \n",
      " pool4_pool (AveragePooling2D)  (None, 1, 1, 896)    0           ['pool4_conv[0][0]']             \n",
      "                                                                                                  \n",
      " conv5_block1_0_bn (BatchNormal  (None, 1, 1, 896)   3584        ['pool4_pool[0][0]']             \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_0_relu (Activatio  (None, 1, 1, 896)   0           ['conv5_block1_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_1_conv (Conv2D)   (None, 1, 1, 128)    114688      ['conv5_block1_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block1_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block1_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block1_concat (Concatena  (None, 1, 1, 928)   0           ['pool4_pool[0][0]',             \n",
      " te)                                                              'conv5_block1_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_0_bn (BatchNormal  (None, 1, 1, 928)   3712        ['conv5_block1_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_0_relu (Activatio  (None, 1, 1, 928)   0           ['conv5_block2_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_1_conv (Conv2D)   (None, 1, 1, 128)    118784      ['conv5_block2_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block2_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block2_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block2_concat (Concatena  (None, 1, 1, 960)   0           ['conv5_block1_concat[0][0]',    \n",
      " te)                                                              'conv5_block2_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_0_bn (BatchNormal  (None, 1, 1, 960)   3840        ['conv5_block2_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_0_relu (Activatio  (None, 1, 1, 960)   0           ['conv5_block3_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_1_conv (Conv2D)   (None, 1, 1, 128)    122880      ['conv5_block3_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block3_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block3_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block3_concat (Concatena  (None, 1, 1, 992)   0           ['conv5_block2_concat[0][0]',    \n",
      " te)                                                              'conv5_block3_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_0_bn (BatchNormal  (None, 1, 1, 992)   3968        ['conv5_block3_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_0_relu (Activatio  (None, 1, 1, 992)   0           ['conv5_block4_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_1_conv (Conv2D)   (None, 1, 1, 128)    126976      ['conv5_block4_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block4_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block4_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block4_concat (Concatena  (None, 1, 1, 1024)  0           ['conv5_block3_concat[0][0]',    \n",
      " te)                                                              'conv5_block4_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_0_bn (BatchNormal  (None, 1, 1, 1024)  4096        ['conv5_block4_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_0_relu (Activatio  (None, 1, 1, 1024)  0           ['conv5_block5_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_1_conv (Conv2D)   (None, 1, 1, 128)    131072      ['conv5_block5_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block5_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block5_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block5_concat (Concatena  (None, 1, 1, 1056)  0           ['conv5_block4_concat[0][0]',    \n",
      " te)                                                              'conv5_block5_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_0_bn (BatchNormal  (None, 1, 1, 1056)  4224        ['conv5_block5_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_0_relu (Activatio  (None, 1, 1, 1056)  0           ['conv5_block6_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_1_conv (Conv2D)   (None, 1, 1, 128)    135168      ['conv5_block6_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block6_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block6_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block6_concat (Concatena  (None, 1, 1, 1088)  0           ['conv5_block5_concat[0][0]',    \n",
      " te)                                                              'conv5_block6_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_0_bn (BatchNormal  (None, 1, 1, 1088)  4352        ['conv5_block6_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_0_relu (Activatio  (None, 1, 1, 1088)  0           ['conv5_block7_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_1_conv (Conv2D)   (None, 1, 1, 128)    139264      ['conv5_block7_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block7_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block7_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block7_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block7_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block7_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block7_concat (Concatena  (None, 1, 1, 1120)  0           ['conv5_block6_concat[0][0]',    \n",
      " te)                                                              'conv5_block7_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_0_bn (BatchNormal  (None, 1, 1, 1120)  4480        ['conv5_block7_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_0_relu (Activatio  (None, 1, 1, 1120)  0           ['conv5_block8_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_1_conv (Conv2D)   (None, 1, 1, 128)    143360      ['conv5_block8_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block8_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block8_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block8_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block8_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block8_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block8_concat (Concatena  (None, 1, 1, 1152)  0           ['conv5_block7_concat[0][0]',    \n",
      " te)                                                              'conv5_block8_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_0_bn (BatchNormal  (None, 1, 1, 1152)  4608        ['conv5_block8_concat[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_0_relu (Activatio  (None, 1, 1, 1152)  0           ['conv5_block9_0_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_1_conv (Conv2D)   (None, 1, 1, 128)    147456      ['conv5_block9_0_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_1_bn (BatchNormal  (None, 1, 1, 128)   512         ['conv5_block9_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv5_block9_1_relu (Activatio  (None, 1, 1, 128)   0           ['conv5_block9_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv5_block9_2_conv (Conv2D)   (None, 1, 1, 32)     36864       ['conv5_block9_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block9_concat (Concatena  (None, 1, 1, 1184)  0           ['conv5_block8_concat[0][0]',    \n",
      " te)                                                              'conv5_block9_2_conv[0][0]']    \n",
      "                                                                                                  \n",
      " conv5_block10_0_bn (BatchNorma  (None, 1, 1, 1184)  4736        ['conv5_block9_concat[0][0]']    \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_0_relu (Activati  (None, 1, 1, 1184)  0           ['conv5_block10_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_1_conv (Conv2D)  (None, 1, 1, 128)    151552      ['conv5_block10_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block10_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block10_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block10_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block10_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block10_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block10_concat (Concaten  (None, 1, 1, 1216)  0           ['conv5_block9_concat[0][0]',    \n",
      " ate)                                                             'conv5_block10_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_0_bn (BatchNorma  (None, 1, 1, 1216)  4864        ['conv5_block10_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_0_relu (Activati  (None, 1, 1, 1216)  0           ['conv5_block11_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_1_conv (Conv2D)  (None, 1, 1, 128)    155648      ['conv5_block11_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block11_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block11_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block11_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block11_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block11_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block11_concat (Concaten  (None, 1, 1, 1248)  0           ['conv5_block10_concat[0][0]',   \n",
      " ate)                                                             'conv5_block11_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_0_bn (BatchNorma  (None, 1, 1, 1248)  4992        ['conv5_block11_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_0_relu (Activati  (None, 1, 1, 1248)  0           ['conv5_block12_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_1_conv (Conv2D)  (None, 1, 1, 128)    159744      ['conv5_block12_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block12_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block12_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block12_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block12_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block12_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block12_concat (Concaten  (None, 1, 1, 1280)  0           ['conv5_block11_concat[0][0]',   \n",
      " ate)                                                             'conv5_block12_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_0_bn (BatchNorma  (None, 1, 1, 1280)  5120        ['conv5_block12_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_0_relu (Activati  (None, 1, 1, 1280)  0           ['conv5_block13_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_1_conv (Conv2D)  (None, 1, 1, 128)    163840      ['conv5_block13_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block13_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block13_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block13_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block13_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block13_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block13_concat (Concaten  (None, 1, 1, 1312)  0           ['conv5_block12_concat[0][0]',   \n",
      " ate)                                                             'conv5_block13_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_0_bn (BatchNorma  (None, 1, 1, 1312)  5248        ['conv5_block13_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_0_relu (Activati  (None, 1, 1, 1312)  0           ['conv5_block14_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_1_conv (Conv2D)  (None, 1, 1, 128)    167936      ['conv5_block14_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block14_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block14_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block14_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block14_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block14_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block14_concat (Concaten  (None, 1, 1, 1344)  0           ['conv5_block13_concat[0][0]',   \n",
      " ate)                                                             'conv5_block14_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_0_bn (BatchNorma  (None, 1, 1, 1344)  5376        ['conv5_block14_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_0_relu (Activati  (None, 1, 1, 1344)  0           ['conv5_block15_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_1_conv (Conv2D)  (None, 1, 1, 128)    172032      ['conv5_block15_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block15_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block15_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block15_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block15_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block15_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block15_concat (Concaten  (None, 1, 1, 1376)  0           ['conv5_block14_concat[0][0]',   \n",
      " ate)                                                             'conv5_block15_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_0_bn (BatchNorma  (None, 1, 1, 1376)  5504        ['conv5_block15_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_0_relu (Activati  (None, 1, 1, 1376)  0           ['conv5_block16_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_1_conv (Conv2D)  (None, 1, 1, 128)    176128      ['conv5_block16_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block16_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block16_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block16_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block16_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block16_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block16_concat (Concaten  (None, 1, 1, 1408)  0           ['conv5_block15_concat[0][0]',   \n",
      " ate)                                                             'conv5_block16_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block17_0_bn (BatchNorma  (None, 1, 1, 1408)  5632        ['conv5_block16_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block17_0_relu (Activati  (None, 1, 1, 1408)  0           ['conv5_block17_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block17_1_conv (Conv2D)  (None, 1, 1, 128)    180224      ['conv5_block17_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block17_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block17_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block17_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block17_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block17_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block17_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block17_concat (Concaten  (None, 1, 1, 1440)  0           ['conv5_block16_concat[0][0]',   \n",
      " ate)                                                             'conv5_block17_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block18_0_bn (BatchNorma  (None, 1, 1, 1440)  5760        ['conv5_block17_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block18_0_relu (Activati  (None, 1, 1, 1440)  0           ['conv5_block18_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block18_1_conv (Conv2D)  (None, 1, 1, 128)    184320      ['conv5_block18_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block18_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block18_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block18_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block18_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block18_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block18_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block18_concat (Concaten  (None, 1, 1, 1472)  0           ['conv5_block17_concat[0][0]',   \n",
      " ate)                                                             'conv5_block18_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block19_0_bn (BatchNorma  (None, 1, 1, 1472)  5888        ['conv5_block18_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block19_0_relu (Activati  (None, 1, 1, 1472)  0           ['conv5_block19_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block19_1_conv (Conv2D)  (None, 1, 1, 128)    188416      ['conv5_block19_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block19_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block19_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block19_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block19_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block19_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block19_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block19_concat (Concaten  (None, 1, 1, 1504)  0           ['conv5_block18_concat[0][0]',   \n",
      " ate)                                                             'conv5_block19_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block20_0_bn (BatchNorma  (None, 1, 1, 1504)  6016        ['conv5_block19_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block20_0_relu (Activati  (None, 1, 1, 1504)  0           ['conv5_block20_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block20_1_conv (Conv2D)  (None, 1, 1, 128)    192512      ['conv5_block20_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block20_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block20_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block20_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block20_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block20_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block20_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block20_concat (Concaten  (None, 1, 1, 1536)  0           ['conv5_block19_concat[0][0]',   \n",
      " ate)                                                             'conv5_block20_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block21_0_bn (BatchNorma  (None, 1, 1, 1536)  6144        ['conv5_block20_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block21_0_relu (Activati  (None, 1, 1, 1536)  0           ['conv5_block21_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block21_1_conv (Conv2D)  (None, 1, 1, 128)    196608      ['conv5_block21_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block21_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block21_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block21_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block21_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block21_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block21_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block21_concat (Concaten  (None, 1, 1, 1568)  0           ['conv5_block20_concat[0][0]',   \n",
      " ate)                                                             'conv5_block21_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block22_0_bn (BatchNorma  (None, 1, 1, 1568)  6272        ['conv5_block21_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block22_0_relu (Activati  (None, 1, 1, 1568)  0           ['conv5_block22_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block22_1_conv (Conv2D)  (None, 1, 1, 128)    200704      ['conv5_block22_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block22_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block22_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block22_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block22_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block22_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block22_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block22_concat (Concaten  (None, 1, 1, 1600)  0           ['conv5_block21_concat[0][0]',   \n",
      " ate)                                                             'conv5_block22_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block23_0_bn (BatchNorma  (None, 1, 1, 1600)  6400        ['conv5_block22_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block23_0_relu (Activati  (None, 1, 1, 1600)  0           ['conv5_block23_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block23_1_conv (Conv2D)  (None, 1, 1, 128)    204800      ['conv5_block23_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block23_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block23_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block23_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block23_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block23_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block23_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block23_concat (Concaten  (None, 1, 1, 1632)  0           ['conv5_block22_concat[0][0]',   \n",
      " ate)                                                             'conv5_block23_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block24_0_bn (BatchNorma  (None, 1, 1, 1632)  6528        ['conv5_block23_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block24_0_relu (Activati  (None, 1, 1, 1632)  0           ['conv5_block24_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block24_1_conv (Conv2D)  (None, 1, 1, 128)    208896      ['conv5_block24_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block24_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block24_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block24_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block24_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block24_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block24_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block24_concat (Concaten  (None, 1, 1, 1664)  0           ['conv5_block23_concat[0][0]',   \n",
      " ate)                                                             'conv5_block24_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block25_0_bn (BatchNorma  (None, 1, 1, 1664)  6656        ['conv5_block24_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block25_0_relu (Activati  (None, 1, 1, 1664)  0           ['conv5_block25_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block25_1_conv (Conv2D)  (None, 1, 1, 128)    212992      ['conv5_block25_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block25_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block25_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block25_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block25_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block25_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block25_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block25_concat (Concaten  (None, 1, 1, 1696)  0           ['conv5_block24_concat[0][0]',   \n",
      " ate)                                                             'conv5_block25_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block26_0_bn (BatchNorma  (None, 1, 1, 1696)  6784        ['conv5_block25_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block26_0_relu (Activati  (None, 1, 1, 1696)  0           ['conv5_block26_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block26_1_conv (Conv2D)  (None, 1, 1, 128)    217088      ['conv5_block26_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block26_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block26_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block26_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block26_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block26_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block26_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block26_concat (Concaten  (None, 1, 1, 1728)  0           ['conv5_block25_concat[0][0]',   \n",
      " ate)                                                             'conv5_block26_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block27_0_bn (BatchNorma  (None, 1, 1, 1728)  6912        ['conv5_block26_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block27_0_relu (Activati  (None, 1, 1, 1728)  0           ['conv5_block27_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block27_1_conv (Conv2D)  (None, 1, 1, 128)    221184      ['conv5_block27_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block27_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block27_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block27_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block27_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block27_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block27_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block27_concat (Concaten  (None, 1, 1, 1760)  0           ['conv5_block26_concat[0][0]',   \n",
      " ate)                                                             'conv5_block27_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block28_0_bn (BatchNorma  (None, 1, 1, 1760)  7040        ['conv5_block27_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block28_0_relu (Activati  (None, 1, 1, 1760)  0           ['conv5_block28_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block28_1_conv (Conv2D)  (None, 1, 1, 128)    225280      ['conv5_block28_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block28_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block28_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block28_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block28_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block28_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block28_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block28_concat (Concaten  (None, 1, 1, 1792)  0           ['conv5_block27_concat[0][0]',   \n",
      " ate)                                                             'conv5_block28_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block29_0_bn (BatchNorma  (None, 1, 1, 1792)  7168        ['conv5_block28_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block29_0_relu (Activati  (None, 1, 1, 1792)  0           ['conv5_block29_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block29_1_conv (Conv2D)  (None, 1, 1, 128)    229376      ['conv5_block29_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block29_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block29_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block29_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block29_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block29_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block29_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block29_concat (Concaten  (None, 1, 1, 1824)  0           ['conv5_block28_concat[0][0]',   \n",
      " ate)                                                             'conv5_block29_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block30_0_bn (BatchNorma  (None, 1, 1, 1824)  7296        ['conv5_block29_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block30_0_relu (Activati  (None, 1, 1, 1824)  0           ['conv5_block30_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block30_1_conv (Conv2D)  (None, 1, 1, 128)    233472      ['conv5_block30_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block30_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block30_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block30_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block30_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block30_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block30_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block30_concat (Concaten  (None, 1, 1, 1856)  0           ['conv5_block29_concat[0][0]',   \n",
      " ate)                                                             'conv5_block30_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block31_0_bn (BatchNorma  (None, 1, 1, 1856)  7424        ['conv5_block30_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block31_0_relu (Activati  (None, 1, 1, 1856)  0           ['conv5_block31_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block31_1_conv (Conv2D)  (None, 1, 1, 128)    237568      ['conv5_block31_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block31_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block31_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block31_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block31_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block31_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block31_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block31_concat (Concaten  (None, 1, 1, 1888)  0           ['conv5_block30_concat[0][0]',   \n",
      " ate)                                                             'conv5_block31_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block32_0_bn (BatchNorma  (None, 1, 1, 1888)  7552        ['conv5_block31_concat[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block32_0_relu (Activati  (None, 1, 1, 1888)  0           ['conv5_block32_0_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block32_1_conv (Conv2D)  (None, 1, 1, 128)    241664      ['conv5_block32_0_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block32_1_bn (BatchNorma  (None, 1, 1, 128)   512         ['conv5_block32_1_conv[0][0]']   \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " conv5_block32_1_relu (Activati  (None, 1, 1, 128)   0           ['conv5_block32_1_bn[0][0]']     \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " conv5_block32_2_conv (Conv2D)  (None, 1, 1, 32)     36864       ['conv5_block32_1_relu[0][0]']   \n",
      "                                                                                                  \n",
      " conv5_block32_concat (Concaten  (None, 1, 1, 1920)  0           ['conv5_block31_concat[0][0]',   \n",
      " ate)                                                             'conv5_block32_2_conv[0][0]']   \n",
      "                                                                                                  \n",
      " bn (BatchNormalization)        (None, 1, 1, 1920)   7680        ['conv5_block32_concat[0][0]']   \n",
      "                                                                                                  \n",
      " relu (Activation)              (None, 1, 1, 1920)   0           ['bn[0][0]']                     \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePooling  (None, 1920)        0           ['relu[0][0]']                   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " predictions (Dense)            (None, 100)          192100      ['avg_pool[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18,514,084\n",
      "Trainable params: 18,285,028\n",
      "Non-trainable params: 229,056\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_temp.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "344e54fa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-452a236eda0b580a\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-452a236eda0b580a\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-17_00_36 MiniModel_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5724b891",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6a2afc988e9c05f4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6a2afc988e9c05f4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir '/home/jack/ml/my_env/my_environment/my_environment/my_logs/run_2021_12_29-18_48_40 SmallForcedLearner_Cifar100'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90930dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
